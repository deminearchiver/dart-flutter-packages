// Copyright (c) 2025 deminearchiver

// AUTO GENERATED FILE, DO NOT EDIT.
//
// Generated by `package:ffigen`.
// ignore_for_file: type=lint, unused_import
import 'dart:ffi' as ffi;

/// -************************************
/// Local Utils
@ffi.Native<ffi.Int Function()>()
external int LZ4_versionNumber();

@ffi.Native<ffi.Pointer<ffi.Char> Function()>()
external ffi.Pointer<ffi.Char> LZ4_versionString();

/// -************************************
/// Simple Functions
/// /
/// /*! LZ4_compress_default() :
/// Compresses 'srcSize' bytes from buffer 'src'
/// into already allocated 'dst' buffer of size 'dstCapacity'.
/// Compression is guaranteed to succeed if 'dstCapacity' >= LZ4_compressBound(srcSize).
/// It also runs faster, so it's a recommended setting.
/// If the function cannot compress 'src' into a more limited 'dst' budget,
/// compression stops *immediately*, and the function result is zero.
/// In which case, 'dst' content is undefined (invalid).
/// srcSize : max supported value is LZ4_MAX_INPUT_SIZE.
/// dstCapacity : size of buffer 'dst' (which must be already allocated)
/// @return  : the number of bytes written into buffer 'dst' (necessarily <= dstCapacity)
/// or 0 if compression fails
/// Note : This function is protected against buffer overflow scenarios (never writes outside 'dst' buffer, nor read outside 'source' buffer).
@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
    ffi.Int,
  )
>()
external int LZ4_compress_default(
  ffi.Pointer<ffi.Char> src,
  ffi.Pointer<ffi.Char> dst,
  int srcSize,
  int dstCapacity,
);

/// ! LZ4_decompress_safe() :
/// @compressedSize : is the exact complete size of the compressed block.
/// @dstCapacity : is the size of destination buffer (which must be already allocated),
/// presumed an upper bound of decompressed size.
/// @return : the number of bytes decompressed into destination buffer (necessarily <= dstCapacity)
/// If destination buffer is not large enough, decoding will stop and output an error code (negative value).
/// If the source stream is detected malformed, the function will stop decoding and return a negative result.
/// Note 1 : This function is protected against malicious data packets :
/// it will never writes outside 'dst' buffer, nor read outside 'source' buffer,
/// even if the compressed block is maliciously modified to order the decoder to do these actions.
/// In such case, the decoder stops immediately, and considers the compressed block malformed.
/// Note 2 : compressedSize and dstCapacity must be provided to the function, the compressed block does not contain them.
/// The implementation is free to send / store / derive this information in whichever way is most beneficial.
/// If there is a need for a different format which bundles together both compressed data and its metadata, consider looking at lz4frame.h instead.
@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
    ffi.Int,
  )
>()
external int LZ4_decompress_safe(
  ffi.Pointer<ffi.Char> src,
  ffi.Pointer<ffi.Char> dst,
  int compressedSize,
  int dstCapacity,
);

/// ! LZ4_compressBound() :
/// Provides the maximum size that LZ4 compression may output in a "worst case" scenario (input data not compressible)
/// This function is primarily useful for memory allocation purposes (destination buffer size).
/// Macro LZ4_COMPRESSBOUND() is also provided for compilation-time evaluation (stack memory allocation for example).
/// Note that LZ4_compress_default() compresses faster when dstCapacity is >= LZ4_compressBound(srcSize)
/// inputSize  : max supported value is LZ4_MAX_INPUT_SIZE
/// return : maximum output size in a "worst case" scenario
/// or 0, if input size is incorrect (too large or negative)
@ffi.Native<ffi.Int Function(ffi.Int)>()
external int LZ4_compressBound(int inputSize);

/// ! LZ4_compress_fast() :
/// Same as LZ4_compress_default(), but allows selection of "acceleration" factor.
/// The larger the acceleration value, the faster the algorithm, but also the lesser the compression.
/// It's a trade-off. It can be fine tuned, with each successive value providing roughly +~3% to speed.
/// An acceleration value of "1" is the same as regular LZ4_compress_default()
/// Values <= 0 will be replaced by LZ4_ACCELERATION_DEFAULT (currently == 1, see lz4.c).
/// Values > LZ4_ACCELERATION_MAX will be replaced by LZ4_ACCELERATION_MAX (currently == 65537, see lz4.c).
@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
  )
>()
external int LZ4_compress_fast(
  ffi.Pointer<ffi.Char> src,
  ffi.Pointer<ffi.Char> dst,
  int srcSize,
  int dstCapacity,
  int acceleration,
);

/// ! LZ4_compress_fast_extState() :
/// Same as LZ4_compress_fast(), using an externally allocated memory space for its state.
/// Use LZ4_sizeofState() to know how much memory must be allocated,
/// and allocate it on 8-bytes boundaries (using `malloc()` typically).
/// Then, provide this buffer as `void* state` to compression function.
@ffi.Native<ffi.Int Function()>()
external int LZ4_sizeofState();

@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
  )
>()
external int LZ4_compress_fast_extState(
  ffi.Pointer<ffi.Void> state,
  ffi.Pointer<ffi.Char> src,
  ffi.Pointer<ffi.Char> dst,
  int srcSize,
  int dstCapacity,
  int acceleration,
);

/// ! LZ4_compress_destSize() :
/// Reverse the logic : compresses as much data as possible from 'src' buffer
/// into already allocated buffer 'dst', of size >= 'dstCapacity'.
/// This function either compresses the entire 'src' content into 'dst' if it's large enough,
/// or fill 'dst' buffer completely with as much data as possible from 'src'.
/// note: acceleration parameter is fixed to "default".
///
/// *srcSizePtr : in+out parameter. Initially contains size of input.
/// Will be modified to indicate how many bytes where read from 'src' to fill 'dst'.
/// New value is necessarily <= input value.
/// @return : Nb bytes written into 'dst' (necessarily <= dstCapacity)
/// or 0 if compression fails.
///
/// Note : 'targetDstSize' must be >= 1, because it's the smallest valid lz4 payload.
///
/// Note 2:from v1.8.2 to v1.9.1, this function had a bug (fixed in v1.9.2+):
/// the produced compressed content could, in rare circumstances,
/// require to be decompressed into a destination buffer
/// larger by at least 1 byte than decompressesSize.
/// If an application uses `LZ4_compress_destSize()`,
/// it's highly recommended to update liblz4 to v1.9.2 or better.
/// If this can't be done or ensured,
/// the receiving decompression function should provide
/// a dstCapacity which is > decompressedSize, by at least 1 byte.
/// See https://github.com/lz4/lz4/issues/859 for details
@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Int>,
    ffi.Int,
  )
>()
external int LZ4_compress_destSize(
  ffi.Pointer<ffi.Char> src,
  ffi.Pointer<ffi.Char> dst,
  ffi.Pointer<ffi.Int> srcSizePtr,
  int targetDstSize,
);

/// ! LZ4_decompress_safe_partial() :
/// Decompress an LZ4 compressed block, of size 'srcSize' at position 'src',
/// into destination buffer 'dst' of size 'dstCapacity'.
/// Up to 'targetOutputSize' bytes will be decoded.
/// The function stops decoding on reaching this objective.
/// This can be useful to boost performance
/// whenever only the beginning of a block is required.
///
/// @return : the number of bytes decoded in `dst` (necessarily <= targetOutputSize)
/// If source stream is detected malformed, function returns a negative result.
///
/// Note 1 : @return can be < targetOutputSize, if compressed block contains less data.
///
/// Note 2 : targetOutputSize must be <= dstCapacity
///
/// Note 3 : this function effectively stops decoding on reaching targetOutputSize,
/// so dstCapacity is kind of redundant.
/// This is because in older versions of this function,
/// decoding operation would still write complete sequences.
/// Therefore, there was no guarantee that it would stop writing at exactly targetOutputSize,
/// it could write more bytes, though only up to dstCapacity.
/// Some "margin" used to be required for this operation to work properly.
/// Thankfully, this is no longer necessary.
/// The function nonetheless keeps the same signature, in an effort to preserve API compatibility.
///
/// Note 4 : If srcSize is the exact size of the block,
/// then targetOutputSize can be any value,
/// including larger than the block's decompressed size.
/// The function will, at most, generate block's decompressed size.
///
/// Note 5 : If srcSize is _larger_ than block's compressed size,
/// then targetOutputSize **MUST** be <= block's decompressed size.
/// Otherwise, *silent corruption will occur*.
@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
  )
>()
external int LZ4_decompress_safe_partial(
  ffi.Pointer<ffi.Char> src,
  ffi.Pointer<ffi.Char> dst,
  int srcSize,
  int targetOutputSize,
  int dstCapacity,
);

@ffi.Native<ffi.Pointer<LZ4_stream_t> Function()>()
external ffi.Pointer<LZ4_stream_t> LZ4_createStream();

@ffi.Native<ffi.Int Function(ffi.Pointer<LZ4_stream_t>)>()
external int LZ4_freeStream(ffi.Pointer<LZ4_stream_t> streamPtr);

/// ! LZ4_resetStream_fast() : v1.9.0+
/// Use this to prepare an LZ4_stream_t for a new chain of dependent blocks
/// (e.g., LZ4_compress_fast_continue()).
///
/// An LZ4_stream_t must be initialized once before usage.
/// This is automatically done when created by LZ4_createStream().
/// However, should the LZ4_stream_t be simply declared on stack (for example),
/// it's necessary to initialize it first, using LZ4_initStream().
///
/// After init, start any new stream with LZ4_resetStream_fast().
/// A same LZ4_stream_t can be re-used multiple times consecutively
/// and compress multiple streams,
/// provided that it starts each new stream with LZ4_resetStream_fast().
///
/// LZ4_resetStream_fast() is much faster than LZ4_initStream(),
/// but is not compatible with memory regions containing garbage data.
///
/// Note: it's only useful to call LZ4_resetStream_fast()
/// in the context of streaming compression.
/// The *extState* functions perform their own resets.
/// Invoking LZ4_resetStream_fast() before is redundant, and even counterproductive.
@ffi.Native<ffi.Void Function(ffi.Pointer<LZ4_stream_t>)>()
external void LZ4_resetStream_fast(ffi.Pointer<LZ4_stream_t> streamPtr);

/// ! LZ4_loadDict() :
/// Use this function to reference a static dictionary into LZ4_stream_t.
/// The dictionary must remain available during compression.
/// LZ4_loadDict() triggers a reset, so any previous data will be forgotten.
/// The same dictionary will have to be loaded on decompression side for successful decoding.
/// Dictionary are useful for better compression of small data (KB range).
/// While LZ4 itself accepts any input as dictionary, dictionary efficiency is also a topic.
/// When in doubt, employ the Zstandard's Dictionary Builder.
/// Loading a size of 0 is allowed, and is the same as reset.
/// @return : loaded dictionary size, in bytes (note: only the last 64 KB are loaded)
@ffi.Native<
  ffi.Int Function(ffi.Pointer<LZ4_stream_t>, ffi.Pointer<ffi.Char>, ffi.Int)
>()
external int LZ4_loadDict(
  ffi.Pointer<LZ4_stream_t> streamPtr,
  ffi.Pointer<ffi.Char> dictionary,
  int dictSize,
);

/// ! LZ4_loadDictSlow() : v1.10.0+
/// Same as LZ4_loadDict(),
/// but uses a bit more cpu to reference the dictionary content more thoroughly.
/// This is expected to slightly improve compression ratio.
/// The extra-cpu cost is likely worth it if the dictionary is re-used across multiple sessions.
/// @return : loaded dictionary size, in bytes (note: only the last 64 KB are loaded)
@ffi.Native<
  ffi.Int Function(ffi.Pointer<LZ4_stream_t>, ffi.Pointer<ffi.Char>, ffi.Int)
>()
external int LZ4_loadDictSlow(
  ffi.Pointer<LZ4_stream_t> streamPtr,
  ffi.Pointer<ffi.Char> dictionary,
  int dictSize,
);

/// ! LZ4_attach_dictionary() : stable since v1.10.0
///
/// This allows efficient re-use of a static dictionary multiple times.
///
/// Rather than re-loading the dictionary buffer into a working context before
/// each compression, or copying a pre-loaded dictionary's LZ4_stream_t into a
/// working LZ4_stream_t, this function introduces a no-copy setup mechanism,
/// in which the working stream references @dictionaryStream in-place.
///
/// Several assumptions are made about the state of @dictionaryStream.
/// Currently, only states which have been prepared by LZ4_loadDict() or
/// LZ4_loadDictSlow() should be expected to work.
///
/// Alternatively, the provided @dictionaryStream may be NULL,
/// in which case any existing dictionary stream is unset.
///
/// If a dictionary is provided, it replaces any pre-existing stream history.
/// The dictionary contents are the only history that can be referenced and
/// logically immediately precede the data compressed in the first subsequent
/// compression call.
///
/// The dictionary will only remain attached to the working stream through the
/// first compression call, at the end of which it is cleared.
/// @dictionaryStream stream (and source buffer) must remain in-place / accessible / unchanged
/// through the completion of the compression session.
///
/// Note: there is no equivalent LZ4_attach_*() method on the decompression side
/// because there is no initialization cost, hence no need to share the cost across multiple sessions.
/// To decompress LZ4 blocks using dictionary, attached or not,
/// just employ the regular LZ4_setStreamDecode() for streaming,
/// or the stateless LZ4_decompress_safe_usingDict() for one-shot decompression.
@ffi.Native<
  ffi.Void Function(ffi.Pointer<LZ4_stream_t>, ffi.Pointer<LZ4_stream_t>)
>()
external void LZ4_attach_dictionary(
  ffi.Pointer<LZ4_stream_t> workingStream,
  ffi.Pointer<LZ4_stream_t> dictionaryStream,
);

/// ! LZ4_compress_fast_continue() :
/// Compress 'src' content using data from previously compressed blocks, for better compression ratio.
/// 'dst' buffer must be already allocated.
/// If dstCapacity >= LZ4_compressBound(srcSize), compression is guaranteed to succeed, and runs faster.
///
/// @return : size of compressed block
/// or 0 if there is an error (typically, cannot fit into 'dst').
///
/// Note 1 : Each invocation to LZ4_compress_fast_continue() generates a new block.
/// Each block has precise boundaries.
/// Each block must be decompressed separately, calling LZ4_decompress_*() with relevant metadata.
/// It's not possible to append blocks together and expect a single invocation of LZ4_decompress_*() to decompress them together.
///
/// Note 2 : The previous 64KB of source data is __assumed__ to remain present, unmodified, at same address in memory !
///
/// Note 3 : When input is structured as a double-buffer, each buffer can have any size, including < 64 KB.
/// Make sure that buffers are separated, by at least one byte.
/// This construction ensures that each block only depends on previous block.
///
/// Note 4 : If input buffer is a ring-buffer, it can have any size, including < 64 KB.
///
/// Note 5 : After an error, the stream status is undefined (invalid), it can only be reset or freed.
@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<LZ4_stream_t>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
  )
>()
external int LZ4_compress_fast_continue(
  ffi.Pointer<LZ4_stream_t> streamPtr,
  ffi.Pointer<ffi.Char> src,
  ffi.Pointer<ffi.Char> dst,
  int srcSize,
  int dstCapacity,
  int acceleration,
);

/// ! LZ4_saveDict() :
/// If last 64KB data cannot be guaranteed to remain available at its current memory location,
/// save it into a safer place (char* safeBuffer).
/// This is schematically equivalent to a memcpy() followed by LZ4_loadDict(),
/// but is much faster, because LZ4_saveDict() doesn't need to rebuild tables.
/// @return : saved dictionary size in bytes (necessarily <= maxDictSize), or 0 if error.
@ffi.Native<
  ffi.Int Function(ffi.Pointer<LZ4_stream_t>, ffi.Pointer<ffi.Char>, ffi.Int)
>()
external int LZ4_saveDict(
  ffi.Pointer<LZ4_stream_t> streamPtr,
  ffi.Pointer<ffi.Char> safeBuffer,
  int maxDictSize,
);

@ffi.Native<ffi.Pointer<LZ4_streamDecode_t> Function()>()
external ffi.Pointer<LZ4_streamDecode_t> LZ4_createStreamDecode();

@ffi.Native<ffi.Int Function(ffi.Pointer<LZ4_streamDecode_t>)>()
external int LZ4_freeStreamDecode(ffi.Pointer<LZ4_streamDecode_t> LZ4_stream);

/// ! LZ4_setStreamDecode() :
/// An LZ4_streamDecode_t context can be allocated once and re-used multiple times.
/// Use this function to start decompression of a new stream of blocks.
/// A dictionary can optionally be set. Use NULL or size 0 for a reset order.
/// Dictionary is presumed stable : it must remain accessible and unmodified during next decompression.
/// @return : 1 if OK, 0 if error
@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<LZ4_streamDecode_t>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
  )
>()
external int LZ4_setStreamDecode(
  ffi.Pointer<LZ4_streamDecode_t> LZ4_streamDecode,
  ffi.Pointer<ffi.Char> dictionary,
  int dictSize,
);

/// ! LZ4_decoderRingBufferSize() : v1.8.2+
/// Note : in a ring buffer scenario (optional),
/// blocks are presumed decompressed next to each other
/// up to the moment there is not enough remaining space for next block (remainingSize < maxBlockSize),
/// at which stage it resumes from beginning of ring buffer.
/// When setting such a ring buffer for streaming decompression,
/// provides the minimum size of this ring buffer
/// to be compatible with any source respecting maxBlockSize condition.
/// @return : minimum ring buffer size,
/// or 0 if there is an error (invalid maxBlockSize).
@ffi.Native<ffi.Int Function(ffi.Int)>()
external int LZ4_decoderRingBufferSize(int maxBlockSize);

/// ! LZ4_decompress_safe_continue() :
/// This decoding function allows decompression of consecutive blocks in "streaming" mode.
/// The difference with the usual independent blocks is that
/// new blocks are allowed to find references into former blocks.
/// A block is an unsplittable entity, and must be presented entirely to the decompression function.
/// LZ4_decompress_safe_continue() only accepts one block at a time.
/// It's modeled after `LZ4_decompress_safe()` and behaves similarly.
///
/// @LZ4_streamDecode : decompression state, tracking the position in memory of past data
/// @compressedSize : exact complete size of one compressed block.
/// @dstCapacity : size of destination buffer (which must be already allocated),
/// must be an upper bound of decompressed size.
/// @return : number of bytes decompressed into destination buffer (necessarily <= dstCapacity)
/// If destination buffer is not large enough, decoding will stop and output an error code (negative value).
/// If the source stream is detected malformed, the function will stop decoding and return a negative result.
///
/// The last 64KB of previously decoded data *must* remain available and unmodified
/// at the memory position where they were previously decoded.
/// If less than 64KB of data has been decoded, all the data must be present.
///
/// Special : if decompression side sets a ring buffer, it must respect one of the following conditions :
/// - Decompression buffer size is _at least_ LZ4_decoderRingBufferSize(maxBlockSize).
/// maxBlockSize is the maximum size of any single block. It can have any value > 16 bytes.
/// In which case, encoding and decoding buffers do not need to be synchronized.
/// Actually, data can be produced by any source compliant with LZ4 format specification, and respecting maxBlockSize.
/// - Synchronized mode :
/// Decompression buffer size is _exactly_ the same as compression buffer size,
/// and follows exactly same update rule (block boundaries at same positions),
/// and decoding function is provided with exact decompressed size of each block (exception for last block of the stream),
/// _then_ decoding & encoding ring buffer can have any size, including small ones ( < 64 KB).
/// - Decompression buffer is larger than encoding buffer, by a minimum of maxBlockSize more bytes.
/// In which case, encoding and decoding buffers do not need to be synchronized,
/// and encoding ring buffer can have any size, including small ones ( < 64 KB).
///
/// Whenever these conditions are not possible,
/// save the last 64KB of decoded data into a safe buffer where it can't be modified during decompression,
/// then indicate where this data is saved using LZ4_setStreamDecode(), before decompressing next block.
@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<LZ4_streamDecode_t>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
    ffi.Int,
  )
>()
external int LZ4_decompress_safe_continue(
  ffi.Pointer<LZ4_streamDecode_t> LZ4_streamDecode,
  ffi.Pointer<ffi.Char> src,
  ffi.Pointer<ffi.Char> dst,
  int srcSize,
  int dstCapacity,
);

/// ! LZ4_decompress_safe_usingDict() :
/// Works the same as
/// a combination of LZ4_setStreamDecode() followed by LZ4_decompress_safe_continue()
/// However, it's stateless: it doesn't need any LZ4_streamDecode_t state.
/// Dictionary is presumed stable : it must remain accessible and unmodified during decompression.
/// Performance tip : Decompression speed can be substantially increased
/// when dst == dictStart + dictSize.
@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
    ffi.Int,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
  )
>()
external int LZ4_decompress_safe_usingDict(
  ffi.Pointer<ffi.Char> src,
  ffi.Pointer<ffi.Char> dst,
  int srcSize,
  int dstCapacity,
  ffi.Pointer<ffi.Char> dictStart,
  int dictSize,
);

/// ! LZ4_decompress_safe_partial_usingDict() :
/// Behaves the same as LZ4_decompress_safe_partial()
/// with the added ability to specify a memory segment for past data.
/// Performance tip : Decompression speed can be substantially increased
/// when dst == dictStart + dictSize.
@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
  )
>()
external int LZ4_decompress_safe_partial_usingDict(
  ffi.Pointer<ffi.Char> src,
  ffi.Pointer<ffi.Char> dst,
  int compressedSize,
  int targetOutputSize,
  int maxOutputSize,
  ffi.Pointer<ffi.Char> dictStart,
  int dictSize,
);

/// ! LZ4_compress_fast_extState_fastReset() :
/// A variant of LZ4_compress_fast_extState().
///
/// Using this variant avoids an expensive initialization step.
/// It is only safe to call if the state buffer is known to be correctly initialized already
/// (see above comment on LZ4_resetStream_fast() for a definition of "correctly initialized").
/// From a high level, the difference is that
/// this function initializes the provided state with a call to something like LZ4_resetStream_fast()
/// while LZ4_compress_fast_extState() starts with a call to LZ4_resetStream().
@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
  )
>()
external int LZ4_compress_fast_extState_fastReset(
  ffi.Pointer<ffi.Void> state,
  ffi.Pointer<ffi.Char> src,
  ffi.Pointer<ffi.Char> dst,
  int srcSize,
  int dstCapacity,
  int acceleration,
);

/// ! LZ4_compress_destSize_extState() : introduced in v1.10.0
/// Same as LZ4_compress_destSize(), but using an externally allocated state.
/// Also: exposes @acceleration
@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Int>,
    ffi.Int,
    ffi.Int,
  )
>()
external int LZ4_compress_destSize_extState(
  ffi.Pointer<ffi.Void> state,
  ffi.Pointer<ffi.Char> src,
  ffi.Pointer<ffi.Char> dst,
  ffi.Pointer<ffi.Int> srcSizePtr,
  int targetDstSize,
  int acceleration,
);

/// ! LZ4_initStream() : v1.9.0+
/// An LZ4_stream_t structure must be initialized at least once.
/// This is automatically done when invoking LZ4_createStream(),
/// but it's not when the structure is simply declared on stack (for example).
///
/// Use LZ4_initStream() to properly initialize a newly declared LZ4_stream_t.
/// It can also initialize any arbitrary buffer of sufficient size,
/// and will @return a pointer of proper type upon initialization.
///
/// Note : initialization fails if size and alignment conditions are not respected.
/// In which case, the function will @return NULL.
/// Note2: An LZ4_stream_t structure guarantees correct alignment and size.
/// Note3: Before v1.9.0, use LZ4_resetStream() instead
@ffi.Native<
  ffi.Pointer<LZ4_stream_t> Function(ffi.Pointer<ffi.Void>, ffi.Size)
>()
external ffi.Pointer<LZ4_stream_t> LZ4_initStream(
  ffi.Pointer<ffi.Void> stateBuffer,
  int size,
);

/// ! Obsolete compression functions (since v1.7.3)
@ffi.Native<
  ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>, ffi.Int)
>()
external int LZ4_compress(
  ffi.Pointer<ffi.Char> src,
  ffi.Pointer<ffi.Char> dest,
  int srcSize,
);

/// =*************************************************
/// Obsolete Functions
/// /
/// /* obsolete compression functions
@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
    ffi.Int,
  )
>()
external int LZ4_compress_limitedOutput(
  ffi.Pointer<ffi.Char> src,
  ffi.Pointer<ffi.Char> dest,
  int srcSize,
  int maxOutputSize,
);

@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
  )
>()
external int LZ4_compress_withState(
  ffi.Pointer<ffi.Void> state,
  ffi.Pointer<ffi.Char> source,
  ffi.Pointer<ffi.Char> dest,
  int inputSize,
);

@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
    ffi.Int,
  )
>()
external int LZ4_compress_limitedOutput_withState(
  ffi.Pointer<ffi.Void> state,
  ffi.Pointer<ffi.Char> source,
  ffi.Pointer<ffi.Char> dest,
  int inputSize,
  int maxOutputSize,
);

@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<LZ4_stream_t>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
  )
>()
external int LZ4_compress_continue(
  ffi.Pointer<LZ4_stream_t> LZ4_streamPtr,
  ffi.Pointer<ffi.Char> source,
  ffi.Pointer<ffi.Char> dest,
  int inputSize,
);

@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<LZ4_stream_t>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
    ffi.Int,
  )
>()
external int LZ4_compress_limitedOutput_continue(
  ffi.Pointer<LZ4_stream_t> LZ4_streamPtr,
  ffi.Pointer<ffi.Char> source,
  ffi.Pointer<ffi.Char> dest,
  int inputSize,
  int maxOutputSize,
);

/// ! Obsolete decompression functions (since v1.8.0)
@ffi.Native<
  ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>, ffi.Int)
>()
external int LZ4_uncompress(
  ffi.Pointer<ffi.Char> source,
  ffi.Pointer<ffi.Char> dest,
  int outputSize,
);

@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
    ffi.Int,
  )
>()
external int LZ4_uncompress_unknownOutputSize(
  ffi.Pointer<ffi.Char> source,
  ffi.Pointer<ffi.Char> dest,
  int isize,
  int maxOutputSize,
);

/// Obsolete streaming functions (since v1.7.0)
/// degraded functionality; do not use!
///
/// In order to perform streaming compression, these functions depended on data
/// that is no longer tracked in the state. They have been preserved as well as
/// possible: using them will still produce a correct output. However, they don't
/// actually retain any history between compression calls. The compression ratio
/// achieved will therefore be no better than compressing each chunk
/// independently.
@ffi.Native<ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Char>)>()
external ffi.Pointer<ffi.Void> LZ4_create(ffi.Pointer<ffi.Char> inputBuffer);

/// Obsolete Streaming functions
@ffi.Native<ffi.Int Function()>()
external int LZ4_sizeofStreamState();

@ffi.Native<ffi.Int Function(ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Char>)>()
external int LZ4_resetStreamState(
  ffi.Pointer<ffi.Void> state,
  ffi.Pointer<ffi.Char> inputBuffer,
);

@ffi.Native<ffi.Pointer<ffi.Char> Function(ffi.Pointer<ffi.Void>)>()
external ffi.Pointer<ffi.Char> LZ4_slideInputBuffer(
  ffi.Pointer<ffi.Void> state,
);

/// ! Obsolete streaming decoding functions (since v1.7.0)
@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
    ffi.Int,
  )
>()
external int LZ4_decompress_safe_withPrefix64k(
  ffi.Pointer<ffi.Char> src,
  ffi.Pointer<ffi.Char> dst,
  int compressedSize,
  int maxDstSize,
);

/// Another obsolete API function, paired with the previous one.
@ffi.Native<
  ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>, ffi.Int)
>()
external int LZ4_decompress_fast_withPrefix64k(
  ffi.Pointer<ffi.Char> src,
  ffi.Pointer<ffi.Char> dst,
  int originalSize,
);

/// ! Obsolete LZ4_decompress_fast variants (since v1.9.0) :
/// These functions used to be faster than LZ4_decompress_safe(),
/// but this is no longer the case. They are now slower.
/// This is because LZ4_decompress_fast() doesn't know the input size,
/// and therefore must progress more cautiously into the input buffer to not read beyond the end of block.
/// On top of that `LZ4_decompress_fast()` is not protected vs malformed or malicious inputs, making it a security liability.
/// As a consequence, LZ4_decompress_fast() is strongly discouraged, and deprecated.
///
/// The last remaining LZ4_decompress_fast() specificity is that
/// it can decompress a block without knowing its compressed size.
/// Such functionality can be achieved in a more secure manner
/// by employing LZ4_decompress_safe_partial().
///
/// Parameters:
/// originalSize : is the uncompressed size to regenerate.
/// `dst` must be already allocated, its size must be >= 'originalSize' bytes.
/// @return : number of bytes read from source buffer (== compressed size).
/// The function expects to finish at block's end exactly.
/// If the source stream is detected malformed, the function stops decoding and returns a negative result.
/// note : LZ4_decompress_fast*() requires originalSize. Thanks to this information, it never writes past the output buffer.
/// However, since it doesn't know its 'src' size, it may read an unknown amount of input, past input buffer bounds.
/// Also, since match offsets are not validated, match reads from 'src' may underflow too.
/// These issues never happen if input (compressed) data is correct.
/// But they may happen if input data is invalid (error or intentional tampering).
/// As a consequence, use these functions in trusted environments with trusted data **only**.
@ffi.Native<
  ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>, ffi.Int)
>()
external int LZ4_decompress_fast(
  ffi.Pointer<ffi.Char> src,
  ffi.Pointer<ffi.Char> dst,
  int originalSize,
);

@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<LZ4_streamDecode_t>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
  )
>()
external int LZ4_decompress_fast_continue(
  ffi.Pointer<LZ4_streamDecode_t> LZ4_streamDecode,
  ffi.Pointer<ffi.Char> src,
  ffi.Pointer<ffi.Char> dst,
  int originalSize,
);

@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
  )
>()
external int LZ4_decompress_fast_usingDict(
  ffi.Pointer<ffi.Char> src,
  ffi.Pointer<ffi.Char> dst,
  int originalSize,
  ffi.Pointer<ffi.Char> dictStart,
  int dictSize,
);

/// ! LZ4_resetStream() :
/// An LZ4_stream_t structure must be initialized at least once.
/// This is done with LZ4_initStream(), or LZ4_resetStream().
/// Consider switching to LZ4_initStream(),
/// invoking LZ4_resetStream() will trigger deprecation warnings in the future.
@ffi.Native<ffi.Void Function(ffi.Pointer<LZ4_stream_t>)>()
external void LZ4_resetStream(ffi.Pointer<LZ4_stream_t> streamPtr);

@ffi.Native<ffi.UnsignedInt Function(LZ4F_errorCode_t)>()
external int LZ4F_isError(int code);

@ffi.Native<ffi.Pointer<ffi.Char> Function(LZ4F_errorCode_t)>()
external ffi.Pointer<ffi.Char> LZ4F_getErrorName(int code);

/// ! LZ4F_compressFrame() :
/// Compress srcBuffer content into an LZ4-compressed frame.
/// It's a one shot operation, all input content is consumed, and all output is generated.
///
/// Note : it's a stateless operation (no LZ4F_cctx state needed).
/// In order to reduce load on the allocator, LZ4F_compressFrame(), by default,
/// uses the stack to allocate space for the compression state and some table.
/// If this usage of the stack is too much for your application,
/// consider compiling `lz4frame.c` with compile-time macro LZ4F_HEAPMODE set to 1 instead.
/// All state allocations will use the Heap.
/// It also means each invocation of LZ4F_compressFrame() will trigger several internal alloc/free invocations.
///
/// @dstCapacity MUST be >= LZ4F_compressFrameBound(srcSize, preferencesPtr).
/// @preferencesPtr is optional : one can provide NULL, in which case all preferences are set to default.
/// @return : number of bytes written into dstBuffer.
/// or an error code if it fails (can be tested using LZ4F_isError())
@ffi.Native<
  ffi.Size Function(
    ffi.Pointer<ffi.Void>,
    ffi.Size,
    ffi.Pointer<ffi.Void>,
    ffi.Size,
    ffi.Pointer<LZ4F_preferences_t>,
  )
>()
external int LZ4F_compressFrame(
  ffi.Pointer<ffi.Void> dstBuffer,
  int dstCapacity,
  ffi.Pointer<ffi.Void> srcBuffer,
  int srcSize,
  ffi.Pointer<LZ4F_preferences_t> preferencesPtr,
);

/// ! LZ4F_compressFrameBound() :
/// Returns the maximum possible compressed size with LZ4F_compressFrame() given srcSize and preferences.
/// `preferencesPtr` is optional. It can be replaced by NULL, in which case, the function will assume default preferences.
/// Note : this result is only usable with LZ4F_compressFrame().
/// It may also be relevant to LZ4F_compressUpdate() _only if_ no flush() operation is ever performed.
@ffi.Native<ffi.Size Function(ffi.Size, ffi.Pointer<LZ4F_preferences_t>)>()
external int LZ4F_compressFrameBound(
  int srcSize,
  ffi.Pointer<LZ4F_preferences_t> preferencesPtr,
);

/// ! LZ4F_compressionLevel_max() :
/// @return maximum allowed compression level (currently: 12)
@ffi.Native<ffi.Int Function()>()
external int LZ4F_compressionLevel_max();

@ffi.Native<ffi.UnsignedInt Function()>()
external int LZ4F_getVersion();

/// ! LZ4F_createCompressionContext() :
/// The first thing to do is to create a compressionContext object,
/// which will keep track of operation state during streaming compression.
/// This is achieved using LZ4F_createCompressionContext(), which takes as argument a version,
/// and a pointer to LZ4F_cctx*, to write the resulting pointer into.
/// @version provided MUST be LZ4F_VERSION. It is intended to track potential version mismatch, notably when using DLL.
/// The function provides a pointer to a fully allocated LZ4F_cctx object.
/// @cctxPtr MUST be != NULL.
/// If @return != zero, context creation failed.
/// A created compression context can be employed multiple times for consecutive streaming operations.
/// Once all streaming compression jobs are completed,
/// the state object can be released using LZ4F_freeCompressionContext().
/// Note1 : LZ4F_freeCompressionContext() is always successful. Its return value can be ignored.
/// Note2 : LZ4F_freeCompressionContext() works fine with NULL input pointers (do nothing).
@ffi.Native<
  LZ4F_errorCode_t Function(
    ffi.Pointer<ffi.Pointer<LZ4F_cctx>>,
    ffi.UnsignedInt,
  )
>()
external int LZ4F_createCompressionContext(
  ffi.Pointer<ffi.Pointer<LZ4F_cctx>> cctxPtr,
  int version,
);

@ffi.Native<LZ4F_errorCode_t Function(ffi.Pointer<LZ4F_cctx>)>()
external int LZ4F_freeCompressionContext(ffi.Pointer<LZ4F_cctx> cctx);

/// ! LZ4F_compressBegin() :
/// will write the frame header into dstBuffer.
/// dstCapacity must be >= LZ4F_HEADER_SIZE_MAX bytes.
/// `prefsPtr` is optional : NULL can be provided to set all preferences to default.
/// @return : number of bytes written into dstBuffer for the header
/// or an error code (which can be tested using LZ4F_isError())
@ffi.Native<
  ffi.Size Function(
    ffi.Pointer<LZ4F_cctx>,
    ffi.Pointer<ffi.Void>,
    ffi.Size,
    ffi.Pointer<LZ4F_preferences_t>,
  )
>()
external int LZ4F_compressBegin(
  ffi.Pointer<LZ4F_cctx> cctx,
  ffi.Pointer<ffi.Void> dstBuffer,
  int dstCapacity,
  ffi.Pointer<LZ4F_preferences_t> prefsPtr,
);

/// ! LZ4F_compressBound() :
/// Provides minimum dstCapacity required to guarantee success of
/// LZ4F_compressUpdate(), given a srcSize and preferences, for a worst case scenario.
/// When srcSize==0, LZ4F_compressBound() provides an upper bound for LZ4F_flush() and LZ4F_compressEnd() instead.
/// Note that the result is only valid for a single invocation of LZ4F_compressUpdate().
/// When invoking LZ4F_compressUpdate() multiple times,
/// if the output buffer is gradually filled up instead of emptied and re-used from its start,
/// one must check if there is enough remaining capacity before each invocation, using LZ4F_compressBound().
/// @return is always the same for a srcSize and prefsPtr.
/// prefsPtr is optional : when NULL is provided, preferences will be set to cover worst case scenario.
/// tech details :
/// @return if automatic flushing is not enabled, includes the possibility that internal buffer might already be filled by up to (blockSize-1) bytes.
/// It also includes frame footer (ending + checksum), since it might be generated by LZ4F_compressEnd().
/// @return doesn't include frame header, as it was already generated by LZ4F_compressBegin().
@ffi.Native<ffi.Size Function(ffi.Size, ffi.Pointer<LZ4F_preferences_t>)>()
external int LZ4F_compressBound(
  int srcSize,
  ffi.Pointer<LZ4F_preferences_t> prefsPtr,
);

/// ! LZ4F_compressUpdate() :
/// LZ4F_compressUpdate() can be called repetitively to compress as much data as necessary.
/// Important rule: dstCapacity MUST be large enough to ensure operation success even in worst case situations.
/// This value is provided by LZ4F_compressBound().
/// If this condition is not respected, LZ4F_compress() will fail (result is an errorCode).
/// After an error, the state is left in a UB state, and must be re-initialized or freed.
/// If previously an uncompressed block was written, buffered data is flushed
/// before appending compressed data is continued.
/// `cOptPtr` is optional : NULL can be provided, in which case all options are set to default.
/// @return : number of bytes written into `dstBuffer` (it can be zero, meaning input data was just buffered).
/// or an error code if it fails (which can be tested using LZ4F_isError())
@ffi.Native<
  ffi.Size Function(
    ffi.Pointer<LZ4F_cctx>,
    ffi.Pointer<ffi.Void>,
    ffi.Size,
    ffi.Pointer<ffi.Void>,
    ffi.Size,
    ffi.Pointer<LZ4F_compressOptions_t>,
  )
>()
external int LZ4F_compressUpdate(
  ffi.Pointer<LZ4F_cctx> cctx,
  ffi.Pointer<ffi.Void> dstBuffer,
  int dstCapacity,
  ffi.Pointer<ffi.Void> srcBuffer,
  int srcSize,
  ffi.Pointer<LZ4F_compressOptions_t> cOptPtr,
);

/// ! LZ4F_flush() :
/// When data must be generated and sent immediately, without waiting for a block to be completely filled,
/// it's possible to call LZ4_flush(). It will immediately compress any data buffered within cctx.
/// `dstCapacity` must be large enough to ensure the operation will be successful.
/// `cOptPtr` is optional : it's possible to provide NULL, all options will be set to default.
/// @return : nb of bytes written into dstBuffer (can be zero, when there is no data stored within cctx)
/// or an error code if it fails (which can be tested using LZ4F_isError())
/// Note : LZ4F_flush() is guaranteed to be successful when dstCapacity >= LZ4F_compressBound(0, prefsPtr).
@ffi.Native<
  ffi.Size Function(
    ffi.Pointer<LZ4F_cctx>,
    ffi.Pointer<ffi.Void>,
    ffi.Size,
    ffi.Pointer<LZ4F_compressOptions_t>,
  )
>()
external int LZ4F_flush(
  ffi.Pointer<LZ4F_cctx> cctx,
  ffi.Pointer<ffi.Void> dstBuffer,
  int dstCapacity,
  ffi.Pointer<LZ4F_compressOptions_t> cOptPtr,
);

/// ! LZ4F_compressEnd() :
/// To properly finish an LZ4 frame, invoke LZ4F_compressEnd().
/// It will flush whatever data remained within `cctx` (like LZ4_flush())
/// and properly finalize the frame, with an endMark and a checksum.
/// `cOptPtr` is optional : NULL can be provided, in which case all options will be set to default.
/// @return : nb of bytes written into dstBuffer, necessarily >= 4 (endMark),
/// or an error code if it fails (which can be tested using LZ4F_isError())
/// Note : LZ4F_compressEnd() is guaranteed to be successful when dstCapacity >= LZ4F_compressBound(0, prefsPtr).
/// A successful call to LZ4F_compressEnd() makes `cctx` available again for another compression task.
@ffi.Native<
  ffi.Size Function(
    ffi.Pointer<LZ4F_cctx>,
    ffi.Pointer<ffi.Void>,
    ffi.Size,
    ffi.Pointer<LZ4F_compressOptions_t>,
  )
>()
external int LZ4F_compressEnd(
  ffi.Pointer<LZ4F_cctx> cctx,
  ffi.Pointer<ffi.Void> dstBuffer,
  int dstCapacity,
  ffi.Pointer<LZ4F_compressOptions_t> cOptPtr,
);

/// ! LZ4F_createDecompressionContext() :
/// Create an LZ4F_dctx object, to track all decompression operations.
/// @version provided MUST be LZ4F_VERSION.
/// @dctxPtr MUST be valid.
/// The function fills @dctxPtr with the value of a pointer to an allocated and initialized LZ4F_dctx object.
/// The @return is an errorCode, which can be tested using LZ4F_isError().
/// dctx memory can be released using LZ4F_freeDecompressionContext();
/// Result of LZ4F_freeDecompressionContext() indicates current state of decompressionContext when being released.
/// That is, it should be == 0 if decompression has been completed fully and correctly.
@ffi.Native<
  LZ4F_errorCode_t Function(
    ffi.Pointer<ffi.Pointer<LZ4F_dctx>>,
    ffi.UnsignedInt,
  )
>()
external int LZ4F_createDecompressionContext(
  ffi.Pointer<ffi.Pointer<LZ4F_dctx>> dctxPtr,
  int version,
);

@ffi.Native<LZ4F_errorCode_t Function(ffi.Pointer<LZ4F_dctx>)>()
external int LZ4F_freeDecompressionContext(ffi.Pointer<LZ4F_dctx> dctx);

/// ! LZ4F_headerSize() : v1.9.0+
/// Provide the header size of a frame starting at `src`.
/// `srcSize` must be >= LZ4F_MIN_SIZE_TO_KNOW_HEADER_LENGTH,
/// which is enough to decode the header length.
/// @return : size of frame header
/// or an error code, which can be tested using LZ4F_isError()
/// note : Frame header size is variable, but is guaranteed to be
/// >= LZ4F_HEADER_SIZE_MIN bytes, and <= LZ4F_HEADER_SIZE_MAX bytes.
@ffi.Native<ffi.Size Function(ffi.Pointer<ffi.Void>, ffi.Size)>()
external int LZ4F_headerSize(ffi.Pointer<ffi.Void> src, int srcSize);

/// ! LZ4F_getFrameInfo() :
/// This function extracts frame parameters (max blockSize, dictID, etc.).
/// Its usage is optional: user can also invoke LZ4F_decompress() directly.
///
/// Extracted information will fill an existing LZ4F_frameInfo_t structure.
/// This can be useful for allocation and dictionary identification purposes.
///
/// LZ4F_getFrameInfo() can work in the following situations :
///
/// 1) At the beginning of a new frame, before any invocation of LZ4F_decompress().
/// It will decode header from `srcBuffer`,
/// consuming the header and starting the decoding process.
///
/// Input size must be large enough to contain the full frame header.
/// Frame header size can be known beforehand by LZ4F_headerSize().
/// Frame header size is variable, but is guaranteed to be >= LZ4F_HEADER_SIZE_MIN bytes,
/// and not more than <= LZ4F_HEADER_SIZE_MAX bytes.
/// Hence, blindly providing LZ4F_HEADER_SIZE_MAX bytes or more will always work.
/// It's allowed to provide more input data than the header size,
/// LZ4F_getFrameInfo() will only consume the header.
///
/// If input size is not large enough,
/// aka if it's smaller than header size,
/// function will fail and return an error code.
///
/// 2) After decoding has been started,
/// it's possible to invoke LZ4F_getFrameInfo() anytime
/// to extract already decoded frame parameters stored within dctx.
///
/// Note that, if decoding has barely started,
/// and not yet read enough information to decode the header,
/// LZ4F_getFrameInfo() will fail.
///
/// The number of bytes consumed from srcBuffer will be updated in *srcSizePtr (necessarily <= original value).
/// LZ4F_getFrameInfo() only consumes bytes when decoding has not yet started,
/// and when decoding the header has been successful.
/// Decompression must then resume from (srcBuffer + *srcSizePtr).
///
/// @return : a hint about how many srcSize bytes LZ4F_decompress() expects for next call,
/// or an error code which can be tested using LZ4F_isError().
/// note 1 : in case of error, dctx is not modified. Decoding operation can resume from beginning safely.
/// note 2 : frame parameters are *copied into* an already allocated LZ4F_frameInfo_t structure.
@ffi.Native<
  ffi.Size Function(
    ffi.Pointer<LZ4F_dctx>,
    ffi.Pointer<LZ4F_frameInfo_t>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<ffi.Size>,
  )
>()
external int LZ4F_getFrameInfo(
  ffi.Pointer<LZ4F_dctx> dctx,
  ffi.Pointer<LZ4F_frameInfo_t> frameInfoPtr,
  ffi.Pointer<ffi.Void> srcBuffer,
  ffi.Pointer<ffi.Size> srcSizePtr,
);

/// @brief Incrementally decompresses an LZ4 frame into user-provided buffers.
///
/// Call repeatedly until the return value is 0 (frame fully decoded) or an error is reported.
/// On each call, the function consumes up to *srcSizePtr bytes from @p srcBuffer and
/// produces up to *dstSizePtr bytes into @p dstBuffer. It updates both size pointers with
/// the actual number of bytes consumed/produced. There is no separate flush step.
///
/// Typical loop:
/// - Provide whatever input you have and an available output buffer.
/// - Read how much input was consumed and how much output was produced.
/// - Use the returned value as a hint for how many source bytes are ideal next time.
///
/// @param[in]      dctx        A valid decompression context created by LZ4F_createDecompressionContext().
/// @param[out]     dstBuffer   Destination buffer for decompressed bytes. May change between calls.
/// @param[in,out]  dstSizePtr  In: capacity of @p dstBuffer in bytes. Out: number of bytes written (<= input value).
/// @param[in]      srcBuffer   Source buffer containing (more) compressed data. May point to the middle of a larger buffer.
/// @param[in,out]  srcSizePtr  In: number of available bytes in @p srcBuffer. Out: number of bytes consumed (<= input value).
/// @param[in]      optionsPtr  Optional decompression options; pass NULL for defaults.
///
/// @return See @retval cases.
/// @retval >0  Hint (in bytes) for how many source bytes are ideal to provide on the next call.
/// This also indicates the current frame is not yet complete: the decompressor
/// expects more input, or may require additional output space to make progress.
/// User can always pass any amount of input; this value is only a performance hint.
/// @retval 0   The current frame is fully decoded. If *srcSizePtr is less than the provided value,
/// the unconsumed tail is the start of another frame (if any).
/// @retval error  An error code; test with LZ4F_isError(ret). After an error, dctx is not
/// resumable: call LZ4F_resetDecompressionContext() before reusing it.
///
/// @pre  @p dctx is a valid state created by LZ4F_createDecompressionContext().
/// @post *srcSizePtr and *dstSizePtr are updated with the actual bytes consumed/produced.
/// @p dstBuffer contents in [0, *dstSizePtr) are valid decompressed data.
///
/// @note  The function may not consume all provided input on each call. Always check *srcSizePtr.
/// Present any unconsumed source bytes again on the next call.
/// @note  @p dstBuffer content is overwritten; it does not need to be stable across calls.
/// @note  After finishing a frame (return==0), you may immediately start feeding the next frame
/// into the same @p dctx (optionally, one can use LZ4F_resetDecompressionContext()).
///
/// @warning If you called LZ4F_getFrameInfo() beforehand, you must advance @p srcBuffer and
/// decrease *srcSizePtr by the number of bytes it consumed (the frame header). Failing
/// to do so can cause decompression failure or, worse, silent corruption.
///
/// @see LZ4F_getFrameInfo(), LZ4F_isError(), LZ4F_resetDecompressionContext(),
/// LZ4F_createDecompressionContext(), LZ4F_freeDecompressionContext()
@ffi.Native<
  ffi.Size Function(
    ffi.Pointer<LZ4F_dctx>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<ffi.Size>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<ffi.Size>,
    ffi.Pointer<LZ4F_decompressOptions_t>,
  )
>()
external int LZ4F_decompress(
  ffi.Pointer<LZ4F_dctx> dctx,
  ffi.Pointer<ffi.Void> dstBuffer,
  ffi.Pointer<ffi.Size> dstSizePtr,
  ffi.Pointer<ffi.Void> srcBuffer,
  ffi.Pointer<ffi.Size> srcSizePtr,
  ffi.Pointer<LZ4F_decompressOptions_t> dOptPtr,
);

/// ! LZ4F_resetDecompressionContext() : added in v1.8.0
/// In case of an error, the context is left in "undefined" state.
/// In which case, it's necessary to reset it, before re-using it.
/// This method can also be used to abruptly stop any unfinished decompression,
/// and start a new one using same context resources.
@ffi.Native<ffi.Void Function(ffi.Pointer<LZ4F_dctx>)>()
external void LZ4F_resetDecompressionContext(ffi.Pointer<LZ4F_dctx> dctx);

/// ! LZ4F_compressBegin_usingDict() : stable since v1.10
/// Inits dictionary compression streaming, and writes the frame header into dstBuffer.
/// @dstCapacity must be >= LZ4F_HEADER_SIZE_MAX bytes.
/// @prefsPtr is optional : one may provide NULL as argument,
/// however, it's the only way to provide dictID in the frame header.
/// @dictBuffer must outlive the compression session.
/// @return : number of bytes written into dstBuffer for the header,
/// or an error code (which can be tested using LZ4F_isError())
/// NOTE: The LZ4Frame spec allows each independent block to be compressed with the dictionary,
/// but this entry supports a more limited scenario, where only the first block uses the dictionary.
/// This is still useful for small data, which only need one block anyway.
/// For larger inputs, one may be more interested in LZ4F_compressFrame_usingCDict() below.
@ffi.Native<
  ffi.Size Function(
    ffi.Pointer<LZ4F_cctx>,
    ffi.Pointer<ffi.Void>,
    ffi.Size,
    ffi.Pointer<ffi.Void>,
    ffi.Size,
    ffi.Pointer<LZ4F_preferences_t>,
  )
>()
external int LZ4F_compressBegin_usingDict(
  ffi.Pointer<LZ4F_cctx> cctx,
  ffi.Pointer<ffi.Void> dstBuffer,
  int dstCapacity,
  ffi.Pointer<ffi.Void> dictBuffer,
  int dictSize,
  ffi.Pointer<LZ4F_preferences_t> prefsPtr,
);

/// ! LZ4F_decompress_usingDict() : stable since v1.10
/// Same as LZ4F_decompress(), using a predefined dictionary.
/// Dictionary is used "in place", without any preprocessing.
/// It must remain accessible throughout the entire frame decoding.
@ffi.Native<
  ffi.Size Function(
    ffi.Pointer<LZ4F_dctx>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<ffi.Size>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<ffi.Size>,
    ffi.Pointer<ffi.Void>,
    ffi.Size,
    ffi.Pointer<LZ4F_decompressOptions_t>,
  )
>()
external int LZ4F_decompress_usingDict(
  ffi.Pointer<LZ4F_dctx> dctxPtr,
  ffi.Pointer<ffi.Void> dstBuffer,
  ffi.Pointer<ffi.Size> dstSizePtr,
  ffi.Pointer<ffi.Void> srcBuffer,
  ffi.Pointer<ffi.Size> srcSizePtr,
  ffi.Pointer<ffi.Void> dict,
  int dictSize,
  ffi.Pointer<LZ4F_decompressOptions_t> decompressOptionsPtr,
);

/// ! LZ4_createCDict() : stable since v1.10
/// When compressing multiple messages / blocks using the same dictionary, it's recommended to initialize it just once.
/// LZ4_createCDict() will create a digested dictionary, ready to start future compression operations without startup delay.
/// LZ4_CDict can be created once and shared by multiple threads concurrently, since its usage is read-only.
/// @dictBuffer can be released after LZ4_CDict creation, since its content is copied within CDict.
@ffi.Native<ffi.Pointer<LZ4F_CDict> Function(ffi.Pointer<ffi.Void>, ffi.Size)>()
external ffi.Pointer<LZ4F_CDict> LZ4F_createCDict(
  ffi.Pointer<ffi.Void> dictBuffer,
  int dictSize,
);

@ffi.Native<ffi.Void Function(ffi.Pointer<LZ4F_CDict>)>()
external void LZ4F_freeCDict(ffi.Pointer<LZ4F_CDict> CDict);

/// ! LZ4_compressFrame_usingCDict() : stable since v1.10
/// Compress an entire srcBuffer into a valid LZ4 frame using a digested Dictionary.
/// @cctx must point to a context created by LZ4F_createCompressionContext().
/// If @cdict==NULL, compress without a dictionary.
/// @dstBuffer MUST be >= LZ4F_compressFrameBound(srcSize, preferencesPtr).
/// If this condition is not respected, function will fail (@return an errorCode).
/// The LZ4F_preferences_t structure is optional : one may provide NULL as argument,
/// but it's not recommended, as it's the only way to provide @dictID in the frame header.
/// @return : number of bytes written into dstBuffer.
/// or an error code if it fails (can be tested using LZ4F_isError())
/// Note: for larger inputs generating multiple independent blocks,
/// this entry point uses the dictionary for each block.
@ffi.Native<
  ffi.Size Function(
    ffi.Pointer<LZ4F_cctx>,
    ffi.Pointer<ffi.Void>,
    ffi.Size,
    ffi.Pointer<ffi.Void>,
    ffi.Size,
    ffi.Pointer<LZ4F_CDict>,
    ffi.Pointer<LZ4F_preferences_t>,
  )
>()
external int LZ4F_compressFrame_usingCDict(
  ffi.Pointer<LZ4F_cctx> cctx,
  ffi.Pointer<ffi.Void> dst,
  int dstCapacity,
  ffi.Pointer<ffi.Void> src,
  int srcSize,
  ffi.Pointer<LZ4F_CDict> cdict,
  ffi.Pointer<LZ4F_preferences_t> preferencesPtr,
);

/// ! LZ4F_compressBegin_usingCDict() : stable since v1.10
/// Inits streaming dictionary compression, and writes the frame header into dstBuffer.
/// @dstCapacity must be >= LZ4F_HEADER_SIZE_MAX bytes.
/// @prefsPtr is optional : one may provide NULL as argument,
/// note however that it's the only way to insert a @dictID in the frame header.
/// @cdict must outlive the compression session.
/// @return : number of bytes written into dstBuffer for the header,
/// or an error code, which can be tested using LZ4F_isError().
@ffi.Native<
  ffi.Size Function(
    ffi.Pointer<LZ4F_cctx>,
    ffi.Pointer<ffi.Void>,
    ffi.Size,
    ffi.Pointer<LZ4F_CDict>,
    ffi.Pointer<LZ4F_preferences_t>,
  )
>()
external int LZ4F_compressBegin_usingCDict(
  ffi.Pointer<LZ4F_cctx> cctx,
  ffi.Pointer<ffi.Void> dstBuffer,
  int dstCapacity,
  ffi.Pointer<LZ4F_CDict> cdict,
  ffi.Pointer<LZ4F_preferences_t> prefsPtr,
);

@ffi.Native<ffi.UnsignedInt Function(ffi.Size)>(symbol: 'LZ4F_getErrorCode')
external int _LZ4F_getErrorCode(int functionResult);

LZ4F_errorCodes LZ4F_getErrorCode(int functionResult) =>
    LZ4F_errorCodes.fromValue(_LZ4F_getErrorCode(functionResult));

/// ! LZ4F_getBlockSize() :
/// @return, in scalar format (size_t),
/// the maximum block size associated with @blockSizeID,
/// or an error code (can be tested using LZ4F_isError()) if @blockSizeID is invalid.
@ffi.Native<ffi.Size Function(ffi.UnsignedInt)>(symbol: 'LZ4F_getBlockSize')
external int _LZ4F_getBlockSize(int blockSizeID);

int LZ4F_getBlockSize(LZ4F_blockSizeID_t blockSizeID) =>
    _LZ4F_getBlockSize(blockSizeID.value);

/// ! LZ4F_uncompressedUpdate() :
/// LZ4F_uncompressedUpdate() can be called repetitively to add data stored as uncompressed blocks.
/// Important rule: dstCapacity MUST be large enough to store the entire source buffer as
/// no compression is done for this operation
/// If this condition is not respected, LZ4F_uncompressedUpdate() will fail (result is an errorCode).
/// After an error, the state is left in a UB state, and must be re-initialized or freed.
/// If previously a compressed block was written, buffered data is flushed first,
/// before appending uncompressed data is continued.
/// This operation is only supported when LZ4F_blockIndependent is used.
/// `cOptPtr` is optional : NULL can be provided, in which case all options are set to default.
/// @return : number of bytes written into `dstBuffer` (it can be zero, meaning input data was just buffered).
/// or an error code if it fails (which can be tested using LZ4F_isError())
@ffi.Native<
  ffi.Size Function(
    ffi.Pointer<LZ4F_cctx>,
    ffi.Pointer<ffi.Void>,
    ffi.Size,
    ffi.Pointer<ffi.Void>,
    ffi.Size,
    ffi.Pointer<LZ4F_compressOptions_t>,
  )
>()
external int LZ4F_uncompressedUpdate(
  ffi.Pointer<LZ4F_cctx> cctx,
  ffi.Pointer<ffi.Void> dstBuffer,
  int dstCapacity,
  ffi.Pointer<ffi.Void> srcBuffer,
  int srcSize,
  ffi.Pointer<LZ4F_compressOptions_t> cOptPtr,
);

/// < this constant defers to stdlib's functions
@ffi.Native<LZ4F_CustomMem>()
external final LZ4F_CustomMem LZ4F_defaultCMem;

/// -*********************************
/// Advanced compression functions
@ffi.Native<ffi.Pointer<LZ4F_cctx> Function(LZ4F_CustomMem, ffi.UnsignedInt)>()
external ffi.Pointer<LZ4F_cctx> LZ4F_createCompressionContext_advanced(
  LZ4F_CustomMem customMem,
  int version,
);

@ffi.Native<ffi.Pointer<LZ4F_dctx> Function(LZ4F_CustomMem, ffi.UnsignedInt)>()
external ffi.Pointer<LZ4F_dctx> LZ4F_createDecompressionContext_advanced(
  LZ4F_CustomMem customMem,
  int version,
);

@ffi.Native<
  ffi.Pointer<LZ4F_CDict> Function(
    LZ4F_CustomMem,
    ffi.Pointer<ffi.Void>,
    ffi.Size,
  )
>()
external ffi.Pointer<LZ4F_CDict> LZ4F_createCDict_advanced(
  LZ4F_CustomMem customMem,
  ffi.Pointer<ffi.Void> dictBuffer,
  int dictSize,
);

/// ! Context size inspection : v1.10.1+
/// These functions return the total memory footprint of the provided context.
@ffi.Native<ffi.Size Function(ffi.Pointer<LZ4F_cctx>)>()
external int LZ4F_cctx_size(ffi.Pointer<LZ4F_cctx> cctx);

@ffi.Native<ffi.Size Function(ffi.Pointer<LZ4F_dctx>)>()
external int LZ4F_dctx_size(ffi.Pointer<LZ4F_dctx> dctx);

/// -************************************
/// Block Compression
/// /
/// /*! LZ4_compress_HC() :
/// Compress data from `src` into `dst`, using the powerful but slower "HC" algorithm.
/// `dst` must be already allocated.
/// Compression is guaranteed to succeed if `dstCapacity >= LZ4_compressBound(srcSize)` (see "lz4.h")
/// Max supported `srcSize` value is LZ4_MAX_INPUT_SIZE (see "lz4.h")
/// `compressionLevel` : any value between 1 and LZ4HC_CLEVEL_MAX will work.
/// Values > LZ4HC_CLEVEL_MAX behave the same as LZ4HC_CLEVEL_MAX.
/// @return : the number of bytes written into 'dst'
/// or 0 if compression fails.
@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
  )
>()
external int LZ4_compress_HC(
  ffi.Pointer<ffi.Char> src,
  ffi.Pointer<ffi.Char> dst,
  int srcSize,
  int dstCapacity,
  int compressionLevel,
);

/// ! LZ4_compress_HC_extStateHC() :
/// Same as LZ4_compress_HC(), but using an externally allocated memory segment for `state`.
/// `state` size is provided by LZ4_sizeofStateHC().
/// Memory segment must be aligned on 8-bytes boundaries (which a normal malloc() should do properly).
@ffi.Native<ffi.Int Function()>()
external int LZ4_sizeofStateHC();

@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
  )
>()
external int LZ4_compress_HC_extStateHC(
  ffi.Pointer<ffi.Void> stateHC,
  ffi.Pointer<ffi.Char> src,
  ffi.Pointer<ffi.Char> dst,
  int srcSize,
  int maxDstSize,
  int compressionLevel,
);

/// ! LZ4_compress_HC_destSize() : v1.9.0+
/// Will compress as much data as possible from `src`
/// to fit into `targetDstSize` budget.
/// Result is provided in 2 parts :
/// @return : the number of bytes written into 'dst' (necessarily <= targetDstSize)
/// or 0 if compression fails.
/// `srcSizePtr` : on success, *srcSizePtr is updated to indicate how much bytes were read from `src`
@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Int>,
    ffi.Int,
    ffi.Int,
  )
>()
external int LZ4_compress_HC_destSize(
  ffi.Pointer<ffi.Void> stateHC,
  ffi.Pointer<ffi.Char> src,
  ffi.Pointer<ffi.Char> dst,
  ffi.Pointer<ffi.Int> srcSizePtr,
  int targetDstSize,
  int compressionLevel,
);

/// ! LZ4_createStreamHC() and LZ4_freeStreamHC() :
/// These functions create and release memory for LZ4 HC streaming state.
/// Newly created states are automatically initialized.
/// A same state can be used multiple times consecutively,
/// starting with LZ4_resetStreamHC_fast() to start a new stream of blocks.
@ffi.Native<ffi.Pointer<LZ4_streamHC_t> Function()>()
external ffi.Pointer<LZ4_streamHC_t> LZ4_createStreamHC();

@ffi.Native<ffi.Int Function(ffi.Pointer<LZ4_streamHC_t>)>()
external int LZ4_freeStreamHC(ffi.Pointer<LZ4_streamHC_t> streamHCPtr);

/// These functions compress data in successive blocks of any size,
/// using previous blocks as dictionary, to improve compression ratio.
/// One key assumption is that previous blocks (up to 64 KB) remain read-accessible while compressing next blocks.
/// There is an exception for ring buffers, which can be smaller than 64 KB.
/// Ring-buffer scenario is automatically detected and handled within LZ4_compress_HC_continue().
///
/// Before starting compression, state must be allocated and properly initialized.
/// LZ4_createStreamHC() does both, though compression level is set to LZ4HC_CLEVEL_DEFAULT.
///
/// Selecting the compression level can be done with LZ4_resetStreamHC_fast() (starts a new stream)
/// or LZ4_setCompressionLevel() (anytime, between blocks in the same stream) (experimental).
/// LZ4_resetStreamHC_fast() only works on states which have been properly initialized at least once,
/// which is automatically the case when state is created using LZ4_createStreamHC().
///
/// After reset, a first "fictional block" can be designated as initial dictionary,
/// using LZ4_loadDictHC() (Optional).
/// Note: In order for LZ4_loadDictHC() to create the correct data structure,
/// it is essential to set the compression level _before_ loading the dictionary.
///
/// Invoke LZ4_compress_HC_continue() to compress each successive block.
/// The number of blocks is unlimited.
/// Previous input blocks, including initial dictionary when present,
/// must remain accessible and unmodified during compression.
///
/// It's allowed to update compression level anytime between blocks,
/// using LZ4_setCompressionLevel() (experimental).
///
/// @dst buffer should be sized to handle worst case scenarios
/// (see LZ4_compressBound(), it ensures compression success).
/// In case of failure, the API does not guarantee recovery,
/// so the state _must_ be reset.
/// To ensure compression success
/// whenever @dst buffer size cannot be made >= LZ4_compressBound(),
/// consider using LZ4_compress_HC_continue_destSize().
///
/// Whenever previous input blocks can't be preserved unmodified in-place during compression of next blocks,
/// it's possible to copy the last blocks into a more stable memory space, using LZ4_saveDictHC().
/// Return value of LZ4_saveDictHC() is the size of dictionary effectively saved into 'safeBuffer' (<= 64 KB)
///
/// After completing a streaming compression,
/// it's possible to start a new stream of blocks, using the same LZ4_streamHC_t state,
/// just by resetting it, using LZ4_resetStreamHC_fast().
@ffi.Native<ffi.Void Function(ffi.Pointer<LZ4_streamHC_t>, ffi.Int)>()
external void LZ4_resetStreamHC_fast(
  ffi.Pointer<LZ4_streamHC_t> streamHCPtr,
  int compressionLevel,
);

@ffi.Native<
  ffi.Int Function(ffi.Pointer<LZ4_streamHC_t>, ffi.Pointer<ffi.Char>, ffi.Int)
>()
external int LZ4_loadDictHC(
  ffi.Pointer<LZ4_streamHC_t> streamHCPtr,
  ffi.Pointer<ffi.Char> dictionary,
  int dictSize,
);

@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<LZ4_streamHC_t>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
    ffi.Int,
  )
>()
external int LZ4_compress_HC_continue(
  ffi.Pointer<LZ4_streamHC_t> streamHCPtr,
  ffi.Pointer<ffi.Char> src,
  ffi.Pointer<ffi.Char> dst,
  int srcSize,
  int maxDstSize,
);

/// ! LZ4_compress_HC_continue_destSize() : v1.9.0+
/// Similar to LZ4_compress_HC_continue(),
/// but will read as much data as possible from `src`
/// to fit into `targetDstSize` budget.
/// Result is provided into 2 parts :
/// @return : the number of bytes written into 'dst' (necessarily <= targetDstSize)
/// or 0 if compression fails.
/// `srcSizePtr` : on success, *srcSizePtr will be updated to indicate how much bytes were read from `src`.
/// Note that this function may not consume the entire input.
@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<LZ4_streamHC_t>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Int>,
    ffi.Int,
  )
>()
external int LZ4_compress_HC_continue_destSize(
  ffi.Pointer<LZ4_streamHC_t> LZ4_streamHCPtr,
  ffi.Pointer<ffi.Char> src,
  ffi.Pointer<ffi.Char> dst,
  ffi.Pointer<ffi.Int> srcSizePtr,
  int targetDstSize,
);

@ffi.Native<
  ffi.Int Function(ffi.Pointer<LZ4_streamHC_t>, ffi.Pointer<ffi.Char>, ffi.Int)
>()
external int LZ4_saveDictHC(
  ffi.Pointer<LZ4_streamHC_t> streamHCPtr,
  ffi.Pointer<ffi.Char> safeBuffer,
  int maxDictSize,
);

/// ! LZ4_attach_HC_dictionary() : stable since v1.10.0
/// This API allows for the efficient re-use of a static dictionary many times.
///
/// Rather than re-loading the dictionary buffer into a working context before
/// each compression, or copying a pre-loaded dictionary's LZ4_streamHC_t into a
/// working LZ4_streamHC_t, this function introduces a no-copy setup mechanism,
/// in which the working stream references the dictionary stream in-place.
///
/// Several assumptions are made about the state of the dictionary stream.
/// Currently, only streams which have been prepared by LZ4_loadDictHC() should
/// be expected to work.
///
/// Alternatively, the provided dictionary stream pointer may be NULL, in which
/// case any existing dictionary stream is unset.
///
/// A dictionary should only be attached to a stream without any history (i.e.,
/// a stream that has just been reset).
///
/// The dictionary will remain attached to the working stream only for the
/// current stream session. Calls to LZ4_resetStreamHC(_fast) will remove the
/// dictionary context association from the working stream. The dictionary
/// stream (and source buffer) must remain in-place / accessible / unchanged
/// through the lifetime of the stream session.
@ffi.Native<
  ffi.Void Function(ffi.Pointer<LZ4_streamHC_t>, ffi.Pointer<LZ4_streamHC_t>)
>()
external void LZ4_attach_HC_dictionary(
  ffi.Pointer<LZ4_streamHC_t> working_stream,
  ffi.Pointer<LZ4_streamHC_t> dictionary_stream,
);

/// LZ4_initStreamHC() : v1.9.0+
/// Required before first use of a statically allocated LZ4_streamHC_t.
/// Before v1.9.0 : use LZ4_resetStreamHC() instead
@ffi.Native<
  ffi.Pointer<LZ4_streamHC_t> Function(ffi.Pointer<ffi.Void>, ffi.Size)
>()
external ffi.Pointer<LZ4_streamHC_t> LZ4_initStreamHC(
  ffi.Pointer<ffi.Void> buffer,
  int size,
);

/// deprecated compression functions
@ffi.Native<
  ffi.Int Function(ffi.Pointer<ffi.Char>, ffi.Pointer<ffi.Char>, ffi.Int)
>()
external int LZ4_compressHC(
  ffi.Pointer<ffi.Char> source,
  ffi.Pointer<ffi.Char> dest,
  int inputSize,
);

@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
    ffi.Int,
  )
>()
external int LZ4_compressHC_limitedOutput(
  ffi.Pointer<ffi.Char> source,
  ffi.Pointer<ffi.Char> dest,
  int inputSize,
  int maxOutputSize,
);

@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
    ffi.Int,
  )
>()
external int LZ4_compressHC2(
  ffi.Pointer<ffi.Char> source,
  ffi.Pointer<ffi.Char> dest,
  int inputSize,
  int compressionLevel,
);

@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
  )
>()
external int LZ4_compressHC2_limitedOutput(
  ffi.Pointer<ffi.Char> source,
  ffi.Pointer<ffi.Char> dest,
  int inputSize,
  int maxOutputSize,
  int compressionLevel,
);

@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
  )
>()
external int LZ4_compressHC_withStateHC(
  ffi.Pointer<ffi.Void> state,
  ffi.Pointer<ffi.Char> source,
  ffi.Pointer<ffi.Char> dest,
  int inputSize,
);

@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
    ffi.Int,
  )
>()
external int LZ4_compressHC_limitedOutput_withStateHC(
  ffi.Pointer<ffi.Void> state,
  ffi.Pointer<ffi.Char> source,
  ffi.Pointer<ffi.Char> dest,
  int inputSize,
  int maxOutputSize,
);

@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
    ffi.Int,
  )
>()
external int LZ4_compressHC2_withStateHC(
  ffi.Pointer<ffi.Void> state,
  ffi.Pointer<ffi.Char> source,
  ffi.Pointer<ffi.Char> dest,
  int inputSize,
  int compressionLevel,
);

@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
  )
>()
external int LZ4_compressHC2_limitedOutput_withStateHC(
  ffi.Pointer<ffi.Void> state,
  ffi.Pointer<ffi.Char> source,
  ffi.Pointer<ffi.Char> dest,
  int inputSize,
  int maxOutputSize,
  int compressionLevel,
);

@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<LZ4_streamHC_t>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
  )
>()
external int LZ4_compressHC_continue(
  ffi.Pointer<LZ4_streamHC_t> LZ4_streamHCPtr,
  ffi.Pointer<ffi.Char> source,
  ffi.Pointer<ffi.Char> dest,
  int inputSize,
);

@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<LZ4_streamHC_t>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
    ffi.Int,
  )
>()
external int LZ4_compressHC_limitedOutput_continue(
  ffi.Pointer<LZ4_streamHC_t> LZ4_streamHCPtr,
  ffi.Pointer<ffi.Char> source,
  ffi.Pointer<ffi.Char> dest,
  int inputSize,
  int maxOutputSize,
);

@ffi.Native<ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Char>)>()
external ffi.Pointer<ffi.Void> LZ4_createHC(ffi.Pointer<ffi.Char> inputBuffer);

@ffi.Native<ffi.Int Function(ffi.Pointer<ffi.Void>)>()
external int LZ4_freeHC(ffi.Pointer<ffi.Void> LZ4HC_Data);

@ffi.Native<ffi.Pointer<ffi.Char> Function(ffi.Pointer<ffi.Void>)>()
external ffi.Pointer<ffi.Char> LZ4_slideInputBufferHC(
  ffi.Pointer<ffi.Void> LZ4HC_Data,
);

@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
    ffi.Int,
  )
>()
external int LZ4_compressHC2_continue(
  ffi.Pointer<ffi.Void> LZ4HC_Data,
  ffi.Pointer<ffi.Char> source,
  ffi.Pointer<ffi.Char> dest,
  int inputSize,
  int compressionLevel,
);

@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
  )
>()
external int LZ4_compressHC2_limitedOutput_continue(
  ffi.Pointer<ffi.Void> LZ4HC_Data,
  ffi.Pointer<ffi.Char> source,
  ffi.Pointer<ffi.Char> dest,
  int inputSize,
  int maxOutputSize,
  int compressionLevel,
);

@ffi.Native<ffi.Int Function()>()
external int LZ4_sizeofStreamStateHC();

@ffi.Native<ffi.Int Function(ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Char>)>()
external int LZ4_resetStreamStateHC(
  ffi.Pointer<ffi.Void> state,
  ffi.Pointer<ffi.Char> inputBuffer,
);

/// LZ4_resetStreamHC() is now replaced by LZ4_initStreamHC().
/// The intention is to emphasize the difference with LZ4_resetStreamHC_fast(),
/// which is now the recommended function to start a new stream of blocks,
/// but cannot be used to initialize a memory segment containing arbitrary garbage data.
///
/// It is recommended to switch to LZ4_initStreamHC().
/// LZ4_resetStreamHC() will generate deprecation warnings in a future version.
@ffi.Native<ffi.Void Function(ffi.Pointer<LZ4_streamHC_t>, ffi.Int)>()
external void LZ4_resetStreamHC(
  ffi.Pointer<LZ4_streamHC_t> streamHCPtr,
  int compressionLevel,
);

/// ! LZ4_setCompressionLevel() : v1.8.0+ (experimental)
/// It's possible to change compression level
/// between successive invocations of LZ4_compress_HC_continue*()
/// for dynamic adaptation.
@ffi.Native<ffi.Void Function(ffi.Pointer<LZ4_streamHC_t>, ffi.Int)>()
external void LZ4_setCompressionLevel(
  ffi.Pointer<LZ4_streamHC_t> LZ4_streamHCPtr,
  int compressionLevel,
);

/// ! LZ4_favorDecompressionSpeed() : v1.8.2+ (experimental)
/// Opt. Parser will favor decompression speed over compression ratio.
/// Only applicable to levels >= LZ4HC_CLEVEL_OPT_MIN.
@ffi.Native<ffi.Void Function(ffi.Pointer<LZ4_streamHC_t>, ffi.Int)>()
external void LZ4_favorDecompressionSpeed(
  ffi.Pointer<LZ4_streamHC_t> LZ4_streamHCPtr,
  int favor,
);

/// ! LZ4_compress_HC_extStateHC_fastReset() :
/// A variant of LZ4_compress_HC_extStateHC().
///
/// Using this variant avoids an expensive initialization step. It is only safe
/// to call if the state buffer is known to be correctly initialized already
/// (see above comment on LZ4_resetStreamHC_fast() for a definition of
/// "correctly initialized"). From a high level, the difference is that this
/// function initializes the provided state with a call to
/// LZ4_resetStreamHC_fast() while LZ4_compress_HC_extStateHC() starts with a
/// call to LZ4_resetStreamHC().
@ffi.Native<
  ffi.Int Function(
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<ffi.Char>,
    ffi.Pointer<ffi.Char>,
    ffi.Int,
    ffi.Int,
    ffi.Int,
  )
>()
external int LZ4_compress_HC_extStateHC_fastReset(
  ffi.Pointer<ffi.Void> state,
  ffi.Pointer<ffi.Char> src,
  ffi.Pointer<ffi.Char> dst,
  int srcSize,
  int dstCapacity,
  int compressionLevel,
);

@ffi.Native<ffi.UnsignedInt Function()>()
external int XXH_versionNumber();

/// ! XXH32() :
/// Calculate the 32-bit hash of sequence "length" bytes stored at memory address "input".
/// The memory between input & input+length must be valid (allocated and read-accessible).
/// "seed" can be used to alter the result predictably.
/// Speed on Core 2 Duo @ 3 GHz (single thread, SMHasher benchmark) : 5.4 GB/s
@ffi.Native<
  XXH32_hash_t Function(ffi.Pointer<ffi.Void>, ffi.Size, ffi.UnsignedInt)
>()
external int XXH32(ffi.Pointer<ffi.Void> input, int length, int seed);

@ffi.Native<ffi.Pointer<XXH32_state_t> Function()>()
external ffi.Pointer<XXH32_state_t> XXH32_createState();

@ffi.Native<ffi.UnsignedInt Function(ffi.Pointer<XXH32_state_t>)>(
  symbol: 'XXH32_freeState',
)
external int _XXH32_freeState(ffi.Pointer<XXH32_state_t> statePtr);

XXH_errorcode XXH32_freeState(ffi.Pointer<XXH32_state_t> statePtr) =>
    XXH_errorcode.fromValue(_XXH32_freeState(statePtr));

@ffi.Native<
  ffi.Void Function(ffi.Pointer<XXH32_state_t>, ffi.Pointer<XXH32_state_t>)
>()
external void XXH32_copyState(
  ffi.Pointer<XXH32_state_t> dst_state,
  ffi.Pointer<XXH32_state_t> src_state,
);

@ffi.Native<
  ffi.UnsignedInt Function(ffi.Pointer<XXH32_state_t>, ffi.UnsignedInt)
>(symbol: 'XXH32_reset')
external int _XXH32_reset(ffi.Pointer<XXH32_state_t> statePtr, int seed);

XXH_errorcode XXH32_reset(ffi.Pointer<XXH32_state_t> statePtr, int seed) =>
    XXH_errorcode.fromValue(_XXH32_reset(statePtr, seed));

@ffi.Native<
  ffi.UnsignedInt Function(
    ffi.Pointer<XXH32_state_t>,
    ffi.Pointer<ffi.Void>,
    ffi.Size,
  )
>(symbol: 'XXH32_update')
external int _XXH32_update(
  ffi.Pointer<XXH32_state_t> statePtr,
  ffi.Pointer<ffi.Void> input,
  int length,
);

XXH_errorcode XXH32_update(
  ffi.Pointer<XXH32_state_t> statePtr,
  ffi.Pointer<ffi.Void> input,
  int length,
) => XXH_errorcode.fromValue(_XXH32_update(statePtr, input, length));

@ffi.Native<XXH32_hash_t Function(ffi.Pointer<XXH32_state_t>)>()
external int XXH32_digest(ffi.Pointer<XXH32_state_t> statePtr);

@ffi.Native<ffi.Void Function(ffi.Pointer<XXH32_canonical_t>, XXH32_hash_t)>()
external void XXH32_canonicalFromHash(
  ffi.Pointer<XXH32_canonical_t> dst,
  int hash,
);

@ffi.Native<XXH32_hash_t Function(ffi.Pointer<XXH32_canonical_t>)>()
external int XXH32_hashFromCanonical(ffi.Pointer<XXH32_canonical_t> src);

/// ! XXH64() :
/// Calculate the 64-bit hash of sequence of length "len" stored at memory address "input".
/// "seed" can be used to alter the result predictably.
/// This function runs faster on 64-bit systems, but slower on 32-bit systems (see benchmark).
@ffi.Native<
  XXH64_hash_t Function(ffi.Pointer<ffi.Void>, ffi.Size, ffi.UnsignedLongLong)
>()
external int XXH64(ffi.Pointer<ffi.Void> input, int length, int seed);

@ffi.Native<ffi.Pointer<XXH64_state_t> Function()>()
external ffi.Pointer<XXH64_state_t> XXH64_createState();

@ffi.Native<ffi.UnsignedInt Function(ffi.Pointer<XXH64_state_t>)>(
  symbol: 'XXH64_freeState',
)
external int _XXH64_freeState(ffi.Pointer<XXH64_state_t> statePtr);

XXH_errorcode XXH64_freeState(ffi.Pointer<XXH64_state_t> statePtr) =>
    XXH_errorcode.fromValue(_XXH64_freeState(statePtr));

@ffi.Native<
  ffi.Void Function(ffi.Pointer<XXH64_state_t>, ffi.Pointer<XXH64_state_t>)
>()
external void XXH64_copyState(
  ffi.Pointer<XXH64_state_t> dst_state,
  ffi.Pointer<XXH64_state_t> src_state,
);

@ffi.Native<
  ffi.UnsignedInt Function(ffi.Pointer<XXH64_state_t>, ffi.UnsignedLongLong)
>(symbol: 'XXH64_reset')
external int _XXH64_reset(ffi.Pointer<XXH64_state_t> statePtr, int seed);

XXH_errorcode XXH64_reset(ffi.Pointer<XXH64_state_t> statePtr, int seed) =>
    XXH_errorcode.fromValue(_XXH64_reset(statePtr, seed));

@ffi.Native<
  ffi.UnsignedInt Function(
    ffi.Pointer<XXH64_state_t>,
    ffi.Pointer<ffi.Void>,
    ffi.Size,
  )
>(symbol: 'XXH64_update')
external int _XXH64_update(
  ffi.Pointer<XXH64_state_t> statePtr,
  ffi.Pointer<ffi.Void> input,
  int length,
);

XXH_errorcode XXH64_update(
  ffi.Pointer<XXH64_state_t> statePtr,
  ffi.Pointer<ffi.Void> input,
  int length,
) => XXH_errorcode.fromValue(_XXH64_update(statePtr, input, length));

@ffi.Native<XXH64_hash_t Function(ffi.Pointer<XXH64_state_t>)>()
external int XXH64_digest(ffi.Pointer<XXH64_state_t> statePtr);

@ffi.Native<ffi.Void Function(ffi.Pointer<XXH64_canonical_t>, XXH64_hash_t)>()
external void XXH64_canonicalFromHash(
  ffi.Pointer<XXH64_canonical_t> dst,
  int hash,
);

@ffi.Native<XXH64_hash_t Function(ffi.Pointer<XXH64_canonical_t>)>()
external int XXH64_hashFromCanonical(ffi.Pointer<XXH64_canonical_t> src);

typedef LZ4_u32 = ffi.Uint32;
typedef DartLZ4_u32 = int;
typedef LZ4_byte = ffi.UnsignedChar;
typedef DartLZ4_byte = int;

final class LZ4_stream_t_internal extends ffi.Struct {
  @ffi.Array.multi([4096])
  external ffi.Array<LZ4_u32> hashTable;

  external ffi.Pointer<LZ4_byte> dictionary;

  external ffi.Pointer<LZ4_stream_t_internal> dictCtx;

  @LZ4_u32()
  external int currentOffset;

  @LZ4_u32()
  external int tableType;

  @LZ4_u32()
  external int dictSize;
}

final class LZ4_stream_u extends ffi.Union {
  @ffi.Array.multi([16416])
  external ffi.Array<ffi.Char> minStateSize;

  external LZ4_stream_t_internal internal_donotuse;
}

/// -*********************************************
/// Streaming Compression Functions
typedef LZ4_stream_t = LZ4_stream_u;

/// ! LZ4_streamDecode_t :
/// Never ever use below internal definitions directly !
/// These definitions are not API/ABI safe, and may change in future versions.
/// If you need static allocation, declare or allocate an LZ4_streamDecode_t object.
final class LZ4_streamDecode_t_internal extends ffi.Struct {
  external ffi.Pointer<LZ4_byte> externalDict;

  external ffi.Pointer<LZ4_byte> prefixEnd;

  @ffi.Size()
  external int extDictSize;

  @ffi.Size()
  external int prefixSize;
}

final class LZ4_streamDecode_u extends ffi.Union {
  @ffi.Array.multi([32])
  external ffi.Array<ffi.Char> minStateSize;

  external LZ4_streamDecode_t_internal internal_donotuse;
}

/// -**********************************************
/// Streaming Decompression Functions
/// Bufferless synchronous API
typedef LZ4_streamDecode_t = LZ4_streamDecode_u;
typedef LZ4_i8 = ffi.Int8;
typedef DartLZ4_i8 = int;
typedef LZ4_u16 = ffi.Uint16;
typedef DartLZ4_u16 = int;

/// -************************************
/// Error management
typedef LZ4F_errorCode_t = ffi.Size;
typedef DartLZ4F_errorCode_t = int;

/// The larger the block size, the (slightly) better the compression ratio,
/// though there are diminishing returns.
/// Larger blocks also increase memory usage on both compression and decompression sides.
enum LZ4F_blockSizeID_t {
  LZ4F_default(0),
  LZ4F_max64KB(4),
  LZ4F_max256KB(5),
  LZ4F_max1MB(6),
  LZ4F_max4MB(7);

  final int value;
  const LZ4F_blockSizeID_t(this.value);

  static LZ4F_blockSizeID_t fromValue(int value) => switch (value) {
    0 => LZ4F_default,
    4 => LZ4F_max64KB,
    5 => LZ4F_max256KB,
    6 => LZ4F_max1MB,
    7 => LZ4F_max4MB,
    _ => throw ArgumentError('Unknown value for LZ4F_blockSizeID_t: $value'),
  };
}

/// Linked blocks sharply reduce inefficiencies when using small blocks,
/// they compress better.
/// However, some LZ4 decoders are only compatible with independent blocks
enum LZ4F_blockMode_t {
  LZ4F_blockLinked(0),
  LZ4F_blockIndependent(1);

  final int value;
  const LZ4F_blockMode_t(this.value);

  static LZ4F_blockMode_t fromValue(int value) => switch (value) {
    0 => LZ4F_blockLinked,
    1 => LZ4F_blockIndependent,
    _ => throw ArgumentError('Unknown value for LZ4F_blockMode_t: $value'),
  };
}

enum LZ4F_contentChecksum_t {
  LZ4F_noContentChecksum(0),
  LZ4F_contentChecksumEnabled(1);

  final int value;
  const LZ4F_contentChecksum_t(this.value);

  static LZ4F_contentChecksum_t fromValue(int value) => switch (value) {
    0 => LZ4F_noContentChecksum,
    1 => LZ4F_contentChecksumEnabled,
    _ => throw ArgumentError(
      'Unknown value for LZ4F_contentChecksum_t: $value',
    ),
  };
}

enum LZ4F_blockChecksum_t {
  LZ4F_noBlockChecksum(0),
  LZ4F_blockChecksumEnabled(1);

  final int value;
  const LZ4F_blockChecksum_t(this.value);

  static LZ4F_blockChecksum_t fromValue(int value) => switch (value) {
    0 => LZ4F_noBlockChecksum,
    1 => LZ4F_blockChecksumEnabled,
    _ => throw ArgumentError('Unknown value for LZ4F_blockChecksum_t: $value'),
  };
}

enum LZ4F_frameType_t {
  LZ4F_frame(0),
  LZ4F_skippableFrame(1);

  final int value;
  const LZ4F_frameType_t(this.value);

  static LZ4F_frameType_t fromValue(int value) => switch (value) {
    0 => LZ4F_frame,
    1 => LZ4F_skippableFrame,
    _ => throw ArgumentError('Unknown value for LZ4F_frameType_t: $value'),
  };
}

/// ! LZ4F_frameInfo_t :
/// makes it possible to set or read frame parameters.
/// Structure must be first init to 0, using memset() or LZ4F_INIT_FRAMEINFO,
/// setting all parameters to default.
/// It's then possible to update selectively some parameters
final class LZ4F_frameInfo_t extends ffi.Struct {
  /// max64KB, max256KB, max1MB, max4MB; 0 == default (LZ4F_max64KB)
  @ffi.UnsignedInt()
  external int blockSizeIDAsInt;

  LZ4F_blockSizeID_t get blockSizeID =>
      LZ4F_blockSizeID_t.fromValue(blockSizeIDAsInt);

  /// LZ4F_blockLinked, LZ4F_blockIndependent; 0 == default (LZ4F_blockLinked)
  @ffi.UnsignedInt()
  external int blockModeAsInt;

  LZ4F_blockMode_t get blockMode => LZ4F_blockMode_t.fromValue(blockModeAsInt);

  /// 1: add a 32-bit checksum of frame's decompressed data; 0 == default (disabled)
  @ffi.UnsignedInt()
  external int contentChecksumFlagAsInt;

  LZ4F_contentChecksum_t get contentChecksumFlag =>
      LZ4F_contentChecksum_t.fromValue(contentChecksumFlagAsInt);

  /// read-only field : LZ4F_frame or LZ4F_skippableFrame
  @ffi.UnsignedInt()
  external int frameTypeAsInt;

  LZ4F_frameType_t get frameType => LZ4F_frameType_t.fromValue(frameTypeAsInt);

  /// Size of uncompressed content ; 0 == unknown
  @ffi.UnsignedLongLong()
  external int contentSize;

  /// Dictionary ID, sent by compressor to help decoder select correct dictionary; 0 == no dictID provided
  @ffi.UnsignedInt()
  external int dictID;

  /// 1: each block followed by a checksum of block's compressed data; 0 == default (disabled)
  @ffi.UnsignedInt()
  external int blockChecksumFlagAsInt;

  LZ4F_blockChecksum_t get blockChecksumFlag =>
      LZ4F_blockChecksum_t.fromValue(blockChecksumFlagAsInt);
}

/// ! LZ4F_preferences_t :
/// makes it possible to supply advanced compression instructions to streaming interface.
/// Structure must be first init to 0, using memset() or LZ4F_INIT_PREFERENCES,
/// setting all parameters to default.
/// All reserved fields must be set to zero.
final class LZ4F_preferences_t extends ffi.Struct {
  external LZ4F_frameInfo_t frameInfo;

  /// 0: default (fast mode); values > LZ4HC_CLEVEL_MAX count as LZ4HC_CLEVEL_MAX; values < 0 trigger "fast acceleration"
  @ffi.Int()
  external int compressionLevel;

  /// 1: always flush; reduces usage of internal buffers
  @ffi.UnsignedInt()
  external int autoFlush;

  /// 1: parser favors decompression speed vs compression ratio. Only works for high compression modes (>= LZ4HC_CLEVEL_OPT_MIN) */  /* v1.8.2+
  @ffi.UnsignedInt()
  external int favorDecSpeed;

  /// must be zero for forward compatibility
  @ffi.Array.multi([3])
  external ffi.Array<ffi.UnsignedInt> reserved;
}

typedef LZ4F_AllocFunctionFunction =
    ffi.Pointer<ffi.Void> Function(
      ffi.Pointer<ffi.Void> opaqueState,
      ffi.Size size,
    );
typedef DartLZ4F_AllocFunctionFunction =
    ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Void> opaqueState, int size);

/// ! Custom memory allocation : v1.9.4+
/// These prototypes make it possible to pass custom allocation/free functions.
/// LZ4F_customMem is provided at state creation time, using LZ4F_create*_advanced() listed below.
/// All allocation/free operations will be completed using these custom variants instead of regular <stdlib.h> ones.
typedef LZ4F_AllocFunction =
    ffi.Pointer<ffi.NativeFunction<LZ4F_AllocFunctionFunction>>;
typedef LZ4F_CallocFunctionFunction =
    ffi.Pointer<ffi.Void> Function(
      ffi.Pointer<ffi.Void> opaqueState,
      ffi.Size size,
    );
typedef DartLZ4F_CallocFunctionFunction =
    ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Void> opaqueState, int size);
typedef LZ4F_CallocFunction =
    ffi.Pointer<ffi.NativeFunction<LZ4F_CallocFunctionFunction>>;
typedef LZ4F_FreeFunctionFunction =
    ffi.Void Function(
      ffi.Pointer<ffi.Void> opaqueState,
      ffi.Pointer<ffi.Void> address,
    );
typedef DartLZ4F_FreeFunctionFunction =
    void Function(
      ffi.Pointer<ffi.Void> opaqueState,
      ffi.Pointer<ffi.Void> address,
    );
typedef LZ4F_FreeFunction =
    ffi.Pointer<ffi.NativeFunction<LZ4F_FreeFunctionFunction>>;

final class LZ4F_CustomMem extends ffi.Struct {
  external LZ4F_AllocFunction customAlloc;

  /// optional; when not defined, uses customAlloc + memset
  external LZ4F_CallocFunction customCalloc;

  external LZ4F_FreeFunction customFree;

  external ffi.Pointer<ffi.Void> opaqueState;
}

typedef U32 = ffi.Uint32;
typedef DartU32 = int;

final class LZ4HC_CCtx_internal extends ffi.Struct {
  @ffi.Array.multi([32768])
  external ffi.Array<LZ4_u32> hashTable;

  @ffi.Array.multi([65536])
  external ffi.Array<LZ4_u16> chainTable;

  /// next block here to continue on current prefix
  external ffi.Pointer<LZ4_byte> end;

  /// Indexes relative to this position
  external ffi.Pointer<LZ4_byte> prefixStart;

  /// alternate reference for extDict
  external ffi.Pointer<LZ4_byte> dictStart;

  /// below that point, need extDict
  @LZ4_u32()
  external int dictLimit;

  /// below that point, no more history
  @LZ4_u32()
  external int lowLimit;

  /// index from which to continue dictionary update
  @LZ4_u32()
  external int nextToUpdate;

  @ffi.Short()
  external int compressionLevel;

  /// favor decompression speed if this flag set,
  /// otherwise, favor compression ratio
  @LZ4_i8()
  external int favorDecSpeed;

  /// stream has to be fully reset if this flag is set
  @LZ4_i8()
  external int dirty;

  external ffi.Pointer<LZ4HC_CCtx_internal> dictCtx;
}

final class LZ4_streamHC_u extends ffi.Union {
  @ffi.Array.multi([262200])
  external ffi.Array<ffi.Char> minStateSize;

  external LZ4HC_CCtx_internal internal_donotuse;
}

/// -************************************
/// Streaming Compression
/// Bufferless synchronous API
typedef LZ4_streamHC_t = LZ4_streamHC_u;

/// -***************************************************
/// Dictionary compression
final class LZ4F_CDict_s extends ffi.Struct {
  external LZ4F_CustomMem cmem;

  external ffi.Pointer<ffi.Void> dictContent;

  external ffi.Pointer<LZ4_stream_t> fastCtx;

  external ffi.Pointer<LZ4_streamHC_t> HCCtx;
}

/// Loading a dictionary has a cost, since it involves construction of tables.
/// The Bulk processing dictionary API makes it possible to share this cost
/// over an arbitrary number of compression jobs, even concurrently,
/// markedly improving compression latency for these cases.
///
/// Note that there is no corresponding bulk API for the decompression side,
/// because dictionary does not carry any initialization cost for decompression.
/// Use the regular LZ4F_decompress_usingDict() there.
typedef LZ4F_CDict = LZ4F_CDict_s;
typedef BYTE = ffi.Uint8;
typedef DartBYTE = int;
typedef U64 = ffi.Uint64;
typedef DartU64 = int;

final class XXH32_state_s extends ffi.Struct {
  @ffi.Uint32()
  external int total_len_32;

  @ffi.Uint32()
  external int large_len;

  @ffi.Uint32()
  external int v1;

  @ffi.Uint32()
  external int v2;

  @ffi.Uint32()
  external int v3;

  @ffi.Uint32()
  external int v4;

  @ffi.Array.multi([4])
  external ffi.Array<ffi.Uint32> mem32;

  @ffi.Uint32()
  external int memsize;

  /// never read nor write, might be removed in a future version
  @ffi.Uint32()
  external int reserved;
}

/// ======   Streaming   ======
typedef XXH32_state_t = XXH32_state_s;
typedef U16 = ffi.Uint16;
typedef DartU16 = int;

/// -************************************
/// Structures and local types
enum LZ4F_BlockCompressMode_e {
  LZ4B_COMPRESSED(0),
  LZ4B_UNCOMPRESSED(1);

  final int value;
  const LZ4F_BlockCompressMode_e(this.value);

  static LZ4F_BlockCompressMode_e fromValue(int value) => switch (value) {
    0 => LZ4B_COMPRESSED,
    1 => LZ4B_UNCOMPRESSED,
    _ => throw ArgumentError(
      'Unknown value for LZ4F_BlockCompressMode_e: $value',
    ),
  };
}

final class LZ4F_cctx_s extends ffi.Struct {
  external LZ4F_CustomMem cmem;

  external LZ4F_preferences_t prefs;

  @U32()
  external int version;

  /// 0 : compression uninitialized ; 1 : initialized, can compress
  @U32()
  external int cStage;

  external ffi.Pointer<LZ4F_CDict> cdict;

  @ffi.Size()
  external int maxBlockSize;

  @ffi.Size()
  external int maxBufferSize;

  /// internal buffer, for streaming
  external ffi.Pointer<BYTE> tmpBuff;

  /// starting position of data compress within internal buffer (>= tmpBuff)
  external ffi.Pointer<BYTE> tmpIn;

  /// amount of data to compress after tmpIn
  @ffi.Size()
  external int tmpInSize;

  @U64()
  external int totalInSize;

  external XXH32_state_t xxh;

  external ffi.Pointer<ffi.Void> lz4CtxPtr;

  /// sized for: 0 = none, 1 = lz4 ctx, 2 = lz4hc ctx
  @U16()
  external int lz4CtxAlloc;

  /// in use as: 0 = none, 1 = lz4 ctx, 2 = lz4hc ctx
  @U16()
  external int lz4CtxType;

  @ffi.UnsignedInt()
  external int blockCompressModeAsInt;

  LZ4F_BlockCompressMode_e get blockCompressMode =>
      LZ4F_BlockCompressMode_e.fromValue(blockCompressModeAsInt);
}

/// -***********************************
/// Advanced compression functions
typedef LZ4F_cctx = LZ4F_cctx_s;
typedef LZ4F_compressionContext_t = ffi.Pointer<LZ4F_cctx>;

final class LZ4F_compressOptions_t extends ffi.Struct {
  /// 1 == src content will remain present on future calls to LZ4F_compress(); skip copying src content within tmp buffer
  @ffi.UnsignedInt()
  external int stableSrc;

  @ffi.Array.multi([3])
  external ffi.Array<ffi.UnsignedInt> reserved;
}

/// -***************************************************
/// Frame Decompression
enum dStage_t {
  dstage_getFrameHeader(0),
  dstage_storeFrameHeader(1),
  dstage_init(2),
  dstage_getBlockHeader(3),
  dstage_storeBlockHeader(4),
  dstage_copyDirect(5),
  dstage_getBlockChecksum(6),
  dstage_getCBlock(7),
  dstage_storeCBlock(8),
  dstage_flushOut(9),
  dstage_getSuffix(10),
  dstage_storeSuffix(11),
  dstage_getSFrameSize(12),
  dstage_storeSFrameSize(13),
  dstage_skipSkippable(14);

  final int value;
  const dStage_t(this.value);

  static dStage_t fromValue(int value) => switch (value) {
    0 => dstage_getFrameHeader,
    1 => dstage_storeFrameHeader,
    2 => dstage_init,
    3 => dstage_getBlockHeader,
    4 => dstage_storeBlockHeader,
    5 => dstage_copyDirect,
    6 => dstage_getBlockChecksum,
    7 => dstage_getCBlock,
    8 => dstage_storeCBlock,
    9 => dstage_flushOut,
    10 => dstage_getSuffix,
    11 => dstage_storeSuffix,
    12 => dstage_getSFrameSize,
    13 => dstage_storeSFrameSize,
    14 => dstage_skipSkippable,
    _ => throw ArgumentError('Unknown value for dStage_t: $value'),
  };
}

final class LZ4F_dctx_s extends ffi.Struct {
  external LZ4F_CustomMem cmem;

  external LZ4F_frameInfo_t frameInfo;

  @U32()
  external int version;

  @ffi.UnsignedInt()
  external int dStageAsInt;

  dStage_t get dStage => dStage_t.fromValue(dStageAsInt);

  @U64()
  external int frameRemainingSize;

  @ffi.Size()
  external int maxBlockSize;

  @ffi.Size()
  external int maxBufferSize;

  external ffi.Pointer<BYTE> tmpIn;

  @ffi.Size()
  external int tmpInSize;

  @ffi.Size()
  external int tmpInTarget;

  external ffi.Pointer<BYTE> tmpOutBuffer;

  external ffi.Pointer<BYTE> dict;

  @ffi.Size()
  external int dictSize;

  external ffi.Pointer<BYTE> tmpOut;

  @ffi.Size()
  external int tmpOutSize;

  @ffi.Size()
  external int tmpOutStart;

  external XXH32_state_t xxh;

  external XXH32_state_t blockChecksum;

  @ffi.Int()
  external int skipChecksum;

  @ffi.Array.multi([19])
  external ffi.Array<BYTE> header;
}

/// -*********************************
/// Decompression functions
typedef LZ4F_dctx = LZ4F_dctx_s;
typedef LZ4F_decompressionContext_t = ffi.Pointer<LZ4F_dctx>;

final class LZ4F_decompressOptions_t extends ffi.Struct {
  /// pledges that last 64KB decompressed data is present right before @dstBuffer pointer.
  /// This optimization skips internal storage operations.
  /// Once set, this pledge must remain valid up to the end of current frame.
  @ffi.UnsignedInt()
  external int stableDst;

  /// disable checksum calculation and verification, even when one is present in frame, to save CPU time.
  /// Setting this option to 1 once disables all checksums for the rest of the frame.
  @ffi.UnsignedInt()
  external int skipChecksums;

  /// must be set to zero for forward compatibility
  @ffi.UnsignedInt()
  external int reserved1;

  /// idem
  @ffi.UnsignedInt()
  external int reserved0;
}

/// enum list is exposed, to handle specific errors
enum LZ4F_errorCodes {
  LZ4F_OK_NoError(0),
  LZ4F_ERROR_GENERIC(1),
  LZ4F_ERROR_maxBlockSize_invalid(2),
  LZ4F_ERROR_blockMode_invalid(3),
  LZ4F_ERROR_parameter_invalid(4),
  LZ4F_ERROR_compressionLevel_invalid(5),
  LZ4F_ERROR_headerVersion_wrong(6),
  LZ4F_ERROR_blockChecksum_invalid(7),
  LZ4F_ERROR_reservedFlag_set(8),
  LZ4F_ERROR_allocation_failed(9),
  LZ4F_ERROR_srcSize_tooLarge(10),
  LZ4F_ERROR_dstMaxSize_tooSmall(11),
  LZ4F_ERROR_frameHeader_incomplete(12),
  LZ4F_ERROR_frameType_unknown(13),
  LZ4F_ERROR_frameSize_wrong(14),
  LZ4F_ERROR_srcPtr_wrong(15),
  LZ4F_ERROR_decompressionFailed(16),
  LZ4F_ERROR_headerChecksum_invalid(17),
  LZ4F_ERROR_contentChecksum_invalid(18),
  LZ4F_ERROR_frameDecoding_alreadyStarted(19),
  LZ4F_ERROR_compressionState_uninitialized(20),
  LZ4F_ERROR_parameter_null(21),
  LZ4F_ERROR_io_write(22),
  LZ4F_ERROR_io_read(23),
  LZ4F_ERROR_maxCode(24),
  _LZ4F_dummy_error_enum_for_c89_never_used(25);

  final int value;
  const LZ4F_errorCodes(this.value);

  static LZ4F_errorCodes fromValue(int value) => switch (value) {
    0 => LZ4F_OK_NoError,
    1 => LZ4F_ERROR_GENERIC,
    2 => LZ4F_ERROR_maxBlockSize_invalid,
    3 => LZ4F_ERROR_blockMode_invalid,
    4 => LZ4F_ERROR_parameter_invalid,
    5 => LZ4F_ERROR_compressionLevel_invalid,
    6 => LZ4F_ERROR_headerVersion_wrong,
    7 => LZ4F_ERROR_blockChecksum_invalid,
    8 => LZ4F_ERROR_reservedFlag_set,
    9 => LZ4F_ERROR_allocation_failed,
    10 => LZ4F_ERROR_srcSize_tooLarge,
    11 => LZ4F_ERROR_dstMaxSize_tooSmall,
    12 => LZ4F_ERROR_frameHeader_incomplete,
    13 => LZ4F_ERROR_frameType_unknown,
    14 => LZ4F_ERROR_frameSize_wrong,
    15 => LZ4F_ERROR_srcPtr_wrong,
    16 => LZ4F_ERROR_decompressionFailed,
    17 => LZ4F_ERROR_headerChecksum_invalid,
    18 => LZ4F_ERROR_contentChecksum_invalid,
    19 => LZ4F_ERROR_frameDecoding_alreadyStarted,
    20 => LZ4F_ERROR_compressionState_uninitialized,
    21 => LZ4F_ERROR_parameter_null,
    22 => LZ4F_ERROR_io_write,
    23 => LZ4F_ERROR_io_read,
    24 => LZ4F_ERROR_maxCode,
    25 => _LZ4F_dummy_error_enum_for_c89_never_used,
    _ => throw ArgumentError('Unknown value for LZ4F_errorCodes: $value'),
  };
}

enum XXH_errorcode {
  XXH_OK(0),
  XXH_ERROR(1);

  final int value;
  const XXH_errorcode(this.value);

  static XXH_errorcode fromValue(int value) => switch (value) {
    0 => XXH_OK,
    1 => XXH_ERROR,
    _ => throw ArgumentError('Unknown value for XXH_errorcode: $value'),
  };
}

/// -**********************************************************************
/// 32-bit hash
typedef XXH32_hash_t = ffi.UnsignedInt;
typedef DartXXH32_hash_t = int;

/// ======   Canonical representation   ======
final class XXH32_canonical_t extends ffi.Struct {
  @ffi.Array.multi([4])
  external ffi.Array<ffi.UnsignedChar> digest;
}

/// -**********************************************************************
/// 64-bit hash
typedef XXH64_hash_t = ffi.UnsignedLongLong;
typedef DartXXH64_hash_t = int;

final class XXH64_state_s extends ffi.Struct {
  @ffi.Uint64()
  external int total_len;

  @ffi.Uint64()
  external int v1;

  @ffi.Uint64()
  external int v2;

  @ffi.Uint64()
  external int v3;

  @ffi.Uint64()
  external int v4;

  @ffi.Array.multi([4])
  external ffi.Array<ffi.Uint64> mem64;

  @ffi.Uint32()
  external int memsize;

  /// never read nor write, might be removed in a future version
  @ffi.Array.multi([2])
  external ffi.Array<ffi.Uint32> reserved;
}

/// ======   Streaming   ======
typedef XXH64_state_t = XXH64_state_s;

/// ======   Canonical representation   ======
final class XXH64_canonical_t extends ffi.Struct {
  @ffi.Array.multi([8])
  external ffi.Array<ffi.UnsignedChar> digest;
}

const int LZ4_FREESTANDING = 0;

const int LZ4_VERSION_MAJOR = 1;

const int LZ4_VERSION_MINOR = 10;

const int LZ4_VERSION_RELEASE = 0;

const int LZ4_VERSION_NUMBER = 11000;

const String LZ4_VERSION_STRING = '1.10.0';

const int LZ4_MEMORY_USAGE = 14;

const int LZ4_MEMORY_USAGE_MIN = 10;

const int LZ4_MEMORY_USAGE_DEFAULT = 14;

const int LZ4_MEMORY_USAGE_MAX = 20;

const int LZ4_MAX_INPUT_SIZE = 2113929216;

const int LZ4_DISTANCE_MAX = 65535;

const int LZ4_COMPRESS_INPLACE_MARGIN = 65567;

const int LZ4_HASHLOG = 12;

const int LZ4_HASHTABLESIZE = 16384;

const int LZ4_HASH_SIZE_U32 = 4096;

const int LZ4_STREAM_MINSIZE = 16416;

const int LZ4_STREAMDECODE_MINSIZE = 32;

const int LZ4F_VERSION = 100;

const int LZ4F_HEADER_SIZE_MIN = 7;

const int LZ4F_HEADER_SIZE_MAX = 19;

const int LZ4F_BLOCK_HEADER_SIZE = 4;

const int LZ4F_BLOCK_CHECKSUM_SIZE = 4;

const int LZ4F_CONTENT_CHECKSUM_SIZE = 4;

const int LZ4F_ENDMARK_SIZE = 4;

const int LZ4F_MAGICNUMBER = 407708164;

const int LZ4F_MAGIC_SKIPPABLE_START = 407710288;

const int LZ4F_MIN_SIZE_TO_KNOW_HEADER_LENGTH = 5;

const int LZ4HC_CLEVEL_MIN = 2;

const int LZ4HC_CLEVEL_DEFAULT = 9;

const int LZ4HC_CLEVEL_OPT_MIN = 10;

const int LZ4HC_CLEVEL_MAX = 12;

const int LZ4HC_DICTIONARY_LOGSIZE = 16;

const int LZ4HC_MAXD = 65536;

const int LZ4HC_MAXD_MASK = 65535;

const int LZ4HC_HASH_LOG = 15;

const int LZ4HC_HASHTABLESIZE = 32768;

const int LZ4HC_HASH_MASK = 32767;

const int LZ4_STREAMHC_MINSIZE = 262200;

const int XXHASH_H_5627135585666179 = 1;

const int XXH_VERSION_MAJOR = 0;

const int XXH_VERSION_MINOR = 6;

const int XXH_VERSION_RELEASE = 5;

const int XXH_VERSION_NUMBER = 605;
